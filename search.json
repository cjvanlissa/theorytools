[{"path":"https://cjvanlissa.github.io/theorytools/articles/augmented_dags.html","id":"a-basic-dag","dir":"Articles","previous_headings":"","what":"A Basic DAG","title":"Specifying Augmented Directed Acyclic Graphs","text":"usual syntax specifying DAG dagitty R-package something like: several tags can used dagitty. Note quotation marks used tags must double quotes \", makes sense wrap whole DAG syntax single quotes ':","code":"library(dagitty) dagitty(\"dag {   X -> Y   Z -> X   Z -> Y }\") library(dagitty) dagitty('dag {   X [exposure, pos=\"0,1\"]   Y [outcome, pos=\"1,1\"]   Z [unobserved, pos=\"1,0\"]   X -> Y   Z -> X   Z -> Y }')"},{"path":"https://cjvanlissa.github.io/theorytools/articles/augmented_dags.html","id":"augmented-dags-adags","dir":"Articles","previous_headings":"","what":"Augmented DAGs (aDAGs)","title":"Specifying Augmented Directed Acyclic Graphs","text":"augmented specification, add additional properties metadata fields. , detail new property:","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/augmented_dags.html","id":"label-nodesedges","dir":"Articles","previous_headings":"Augmented DAGs (aDAGs)","what":"label (Nodes/Edges)","title":"Specifying Augmented Directed Acyclic Graphs","text":"Usage: Provide descriptive name node edge. Example: X [label=\"Study hours\"] label used, example, tidySEM label nodes edges:","code":"library(tidySEM) g <- dagitty('dag {   X [label=\"Predictor\", pos=\"0,0\"]   Y [label=\"Outcome\", pos=\"1,0\"]   X -> Y [label=\"effect\"] }') graph_sem(g, text_size = 2)"},{"path":"https://cjvanlissa.github.io/theorytools/articles/augmented_dags.html","id":"distribution-nodes","dir":"Articles","previous_headings":"","what":"2. distribution (Nodes)","title":"Specifying Augmented Directed Acyclic Graphs","text":"Usage: References function generates data exogenous variables, describes residual distribution endogenous variables. function can reference argument n determine sample size. example, specify node comprising five groups total sample size n, one use sample.int(n = 5, size = n, replace=TRUE). argument n explicitly provided, theorytools checks n formal argument function, assigns . Examples: X [distribution=\"rnorm()\"]: Node X exogenous variable drawn normal distribution default arguments. Y [distribution=\"rnorm()\"]: Node Y residuals assumed normally distributed default arguments.","code":"g <- dagitty('dag {   X [distribution=\"rbinom(size = 2, prob = .5)\"]   Y [distribution=\"rnorm()\"]   X -> Y [form=\".2*X\"] }')"},{"path":"https://cjvanlissa.github.io/theorytools/articles/augmented_dags.html","id":"form-edges","dir":"Articles","previous_headings":"","what":"3. form (Edges)","title":"Specifying Augmented Directed Acyclic Graphs","text":"Usage: Provides formula-like specification child node depends parent node(s). something .formula() can parse. Examples: X -> Y [form=\".2*X\"] indicates Y linear function .2 times X X -> Y [form=\"X:Z\"] indicates Y depends interaction X Z X -> Y [form=\"X^2\"] indicates Y depends quadratic function X","code":"g <- dagitty('dag {   X [distribution=\"rbinom(size = 2, prob = .5)\"]   Y [distribution=\"rnorm()\"]   X -> Y [form=\".2*X\"] }')"},{"path":"https://cjvanlissa.github.io/theorytools/articles/augmented_dags.html","id":"example-augmented-dag-specification","dir":"Articles","previous_headings":"","what":"Example: Augmented DAG Specification","title":"Specifying Augmented Directed Acyclic Graphs","text":"simple, hypothetical DAG showing combine ideas. DAG posits: X: Number study hours, exposure. Values randomly sampled 1-20 hours. Z: Stress level, exogenous covariate, exponentially distributed (.e., right-skewed, people stressed). Y: Exam performance outcome depending X Z, normally distributed residuals.s","code":"g <- dagitty('dag {   X [exposure,      pos=\"0,0\",      label=\"Study Hours\",      distribution=\"sample.int(n = 20, size = n, replace = TRUE)\"]   Z [label=\"Stress Level\",      pos=\".5,1\",      distribution=\"rexp()\"]   Y [outcome,      pos=\"1,.2\",      label=\"Exam Performance\", distribution=\"rnorm()\"]   X -> Y [label=\"direct\", form=\"0.5+X\"]   X -> Z   Z -> Y [label=\"indirect\", form=\"2*Z\"] }') graph_sem(g, text_size = 3)"},{"path":"https://cjvanlissa.github.io/theorytools/articles/augmented_dags.html","id":"parsing-dag-properties","dir":"Articles","previous_headings":"Example: Augmented DAG Specification","what":"Parsing DAG Properties","title":"Specifying Augmented Directed Acyclic Graphs","text":"Augmented DAGs interoperable dagitty, dagitty package natively aware additional metadata fields used theorytools, like distribution form. access augmented properties aDAGs, theorytools package uses tidySEM. purpose tidySEM package plot graphs (structural equation models DAGs) ggplot objects, can customized using regular ggplot2 code. contains parsing functions extract nodes edges variety objects, including dagitty graphs. functions get_nodes() get_edges() parse nodes edges aDAGs, respectively:","code":"get_nodes(g) #>   name exposure   x   y            label #> 1    X     TRUE 0.0 0.0      Study Hours #> 2    Y       NA 1.0 0.2 Exam Performance #> 3    Z       NA 0.5 1.0     Stress Level #>                                   distribution outcome shape #> 1 sample.int(n = 20, size = n, replace = TRUE)      NA  none #> 2                                      rnorm()    TRUE  none #> 3                                       rexp()      NA  none get_edges(g) #>   from to  e    label     form arrow  color #> 1    X  Y ->   direct -X^2+4*X  last gray80 #> 2    X  Z ->     <NA>     <NA>  last gray80 #> 3    Z  Y -> indirect      2*Z  last gray80"},{"path":"https://cjvanlissa.github.io/theorytools/articles/augmented_dags.html","id":"interpreting-distribution-and-form-in-simulation","dir":"Articles","previous_headings":"","what":"Interpreting distribution and form in Simulation","title":"Specifying Augmented Directed Acyclic Graphs","text":"primary motivation augmented properties simulation. example, might simulate data : Generating X sample.int(n). Generating Z rexp(n). Generating Y using formula includes X Z plus residual rnorm(n). Code simulate data line metadata can automatically generated: illustrate, show scatter plot data simulated using code:  can use script, example, generate synthetic data build reproducible analysis pipeline Preregistration--Code (Peikert, Van Lissa, Brandmaier 2021; Van Lissa 2022).","code":"set.seed(1) cat(simulate_data(g, run = FALSE), sep = \"\\n\") #> # Set random seed #> set.seed(1140350788) #> # Set simulation parameters #> n <- 500 #> # Simulate exogenous nodes #> X <- sample.int(n = 20, size = n, replace = TRUE) #> # Simulate endogenous nodes #> Z <- 0.09 * X + rexp(n = n) #> Y <- 2 * Z + X * (4 - 0.49 * X) + rnorm(n = n) #> df <- data.frame( #> X = X, #> Y = Y, #> Z = Z #> ) df <- simulate_data(g, run = TRUE) ggplot2::ggplot(df, aes(x=X,y=Y,color=Z))+geom_point()"},{"path":"https://cjvanlissa.github.io/theorytools/articles/augmented_dags.html","id":"additional-notes","dir":"Articles","previous_headings":"Interpreting distribution and form in Simulation","what":"Additional Notes","title":"Specifying Augmented Directed Acyclic Graphs","text":"Syntax Quoting: R, rules using quotes within quotes. dagitty package recognizes double quotes (\" \") inside graph specifications. means must wrap graph specification text single quotes (' '). Alternatively, can escape every double quote inside graph specification, recommended hassle. Multiple Parents: node multiple parents, can either specify multiple edges form properties single edge combined formula. combined, unique terms retained. Order Declaration: dagitty mind order nodes declared, ’ll need topological order (cycles) valid DAG generation simulation. Integration dagitty Functions: standard dagitty functions (e.g., adjustmentSets()) look recognized tags like exposure outcome. ignore custom properties like distribution form, interfere normal usage.","code":""},{"path":[]},{"path":"https://cjvanlissa.github.io/theorytools/articles/causal-inference.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using FAIR Theory for Causal Inference","text":"Directed acyclic graphs (DAGs) powerful tool expressing testing causal assumptions. allow researchers identify potential confounders colliders, guide decisions variables control () statistical analyses (Cinelli, Forney, Pearl 2022). DAGs can implemented FAIR theories, can derived FAIR theories. vignette, ’ll illustrate use DAGs causal inference R, inspired Tripartite Model impact family children’s emotion regulation adjustment (Morris et al. 2007).","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/causal-inference.html","id":"learning-goals","dir":"Articles","previous_headings":"Introduction","what":"Learning Goals","title":"Using FAIR Theory for Causal Inference","text":"end tutorial, able : Transform theory represented diagram FAIR theory Access reuse FAIR theory within data analysis environment Generate synthetic data FAIR theory Select control variables using FAIR theory Perform basic causal inference based FAIR theory","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/causal-inference.html","id":"optional-video-lecture","dir":"Articles","previous_headings":"Introduction","what":"Optional: Video Lecture","title":"Using FAIR Theory for Causal Inference","text":"video lecture gives introduction causal inference, focus DAGs comprising three variables, including distinction confounders colliders.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/causal-inference.html","id":"install-and-load-required-packages","dir":"Articles","previous_headings":"","what":"Install and Load Required Packages","title":"Using FAIR Theory for Causal Inference","text":"’ll use following packages: theorytools functions pertaining FAIR theory sample dataset dagitty interacting Directed Acyclic Graphs (DAGs) tidySEM visualizing DAGs run code haven’t already installed packages:","code":"install.packages(\"theorytools\") install.packages(\"dagitty\") install.packages(\"tidySEM\") library(theorytools) library(dagitty) #>  #> Attaching package: 'dagitty' #> The following object is masked from 'package:tidySEM': #>  #>     edges library(tidySEM) library(ggplot2)"},{"path":"https://cjvanlissa.github.io/theorytools/articles/causal-inference.html","id":"the-tripartite-model","dir":"Articles","previous_headings":"","what":"The Tripartite Model","title":"Using FAIR Theory for Causal Inference","text":"tripartite model identifies three major familial influences children’s emotion regulation (ER): Observation (O), e.g., modeling parents’ behavior Parenting practices (PP), e.g., emotion coaching Emotional Family Climate (EC), e.g., attachment style three factors, together parent characteristics (PC) child characteristics (CC), shape child’s emotion regulation (ER), turn influences child’s adjustment () (e.g., internalizing/externalizing problems, social competence). model visually represented : interpretation Morris’ Tripartite Model Emotion Regulation Development figure, loosely based visual representation theory paper Morris et al. (2007) (see Figure 1, p.362). relatively well formalized compared standard developmental psychological theories. can FAIRify theory, however, clarify things, make decisions. First, notice model explicitly follow graphing convention. resembles path diagram, used visualize structural equation model - notice unconnected bold double-headed arrow near CC (Child Characteristics). written description text clarifies meaning bold arrow: authors argue Child Characteristics “moderate relations family context [] ER” (Morris et al., 2007, p. 364). Second, note arrows bidirectional. fine wished specify model structural equation model associations can undirected. However, since goal perform causal inference, need directed acyclic graph. means assume direction causality bidirectional arrows. Reading text helps us direct arrows: read “children learn ER [Observation]”, “parenting practices affect ER”, “ER affected emotional climate”. causal language (Norouzi et al. 2024). Even though later read “ER familial influences bidirectional processes model”, even though recent publications argued child effects parents outweigh parents’ effects children emotional development (Van Lissa Keizer 2020), purpose tutorial, assume parent effects children. fine make strong assumptions specifying theory; inconsistent data, can revise later. Third, note clear path Parenting Practices Adjustment. paths Observation Emotional Climate Adjustment, read text: “although direct effects family context children’s adjustment […] mediational model proposed”. Elsewhere text, “family context” defined terms three predictors (O, PP, EC). can thus either include three direct effects, omit assume full mediation. Since latter option results much simpler DAG, opt full mediation.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/causal-inference.html","id":"implementing-the-tripartite-model-as-a-dag","dir":"Articles","previous_headings":"The Tripartite Model","what":"Implementing the Tripartite Model as a DAG","title":"Using FAIR Theory for Causal Inference","text":"can implement model DAG using dagitty package. start “ontology”, simply, stating constructs exist DAG: Next, add directed edges present original theory: Next, direct edges run Observation, Parenting Practices, Emotional Climate Emotion Regulation. omit direct effects Adjustment, include effect ER Adjustment. Next, incorporate effects Child Characteristics. moderation effects. DAG, interaction effect two predictors outcome simply represented specifying predictors common causes outcome. specifying model, however, may explicitly include interaction effects. can annotate graph way clear variables involved interactions O, PP, EC, like : Note use R’s formula syntax, may already know linear regression models. , specified three interaction terms, specified using interaction operator : connected + operator, means interaction effects form weighted sum. Finally, make decision interrelations predictors emotion regulation. omit , delve literature direct . now, made following assumptions: Emotional Climate specific Parenting Practices affect children’s Observation (=modeling) parents’ behavior Parenting Practices affect Emotional Climate Note final line closes DAG specification, stored variable called tripartite. Now, complete DAG! Quiz  DAG can arrows run left right, arrows run right left, bidirectional arrows. TRUEFALSE interaction effect X1 X2 Y represented DAG drawing directed arrow X1 Y, X2 Y. TRUEFALSE","code":"tripartite <- dagitty('dag { O PP EC PC CC ER A PC -> CC PC -> EC PC -> PP PC -> O O -> ER PP -> ER EC -> ER  ER -> A CC -> ER [form=\"CC:O+CC:PP+CC:EC\"]; PP -> O EC -> O PP -> EC }')"},{"path":"https://cjvanlissa.github.io/theorytools/articles/causal-inference.html","id":"from-dag-to-fair-theory","dir":"Articles","previous_headings":"","what":"From DAG to FAIR Theory","title":"Using FAIR Theory for Causal Inference","text":"DAG yet FAIR theory. can FAIRify DAG specified following steps outlined Making Theory FAIR vignette. briefly go steps . First, let’s save DAG text file: GitHub integration must set next step work. can check everything set correctly running: Next, can create FAIR theory repository: Update README.md file necessary. , go Zenodo, switch archiving GitHub repository. done, run: Finally, can edit metadata archived version Zenodo. following DOI shows version FAIR Tripartite Model: https://doi.org/10.5281/zenodo.14921521","code":"writeLines(tripartite, \"tripartite_model.txt\") worcs::check_git() worcs::check_github() create_fair_theory(   path = file.path(\"c:/theories\", \"tripartite_model\"),   title = \"Tripartite Model\",   theory_file = \"tripartite_model.txt\",   remote_repo = \"tripartite_model\",   add_license = \"cc0\") worcs::git_release_publish(repo = file.path(\"c:/theories\", \"tripartite_model\"))"},{"path":"https://cjvanlissa.github.io/theorytools/articles/causal-inference.html","id":"accessing-an-existing-fair-theory","dir":"Articles","previous_headings":"","what":"Accessing an Existing FAIR Theory","title":"Using FAIR Theory for Causal Inference","text":"several ways can access existing FAIR theory. goal simply use analysis workflow (case tutorial), can access static archived version Zenodo running: want contribute theory development, might instead prefer create local clone Git repository. Note typically good idea first fork original GitHub repository GitHub account, clone fork, instead original author’s version. Regardless, function download_theory() takes Git remote address , case clones theory: difference two approaches former copies statically archived files device, whereas latter copies entire Git repository history commits branches, continues version control changes make. tutorial, please download version Tripartite Model using download_zenodo().","code":"download_theory(   id = \"https://doi.org/10.5281/zenodo.14921521\",   path = \"c:/theories/tripartite_downloaded\") download_theory(   id = \"https://github.com/cjvanlissa/tripartite_model.git\",   path = \"c:/theories/tripartite_clone\")"},{"path":"https://cjvanlissa.github.io/theorytools/articles/causal-inference.html","id":"x-interoperability-in-r","dir":"Articles","previous_headings":"","what":"X-Interoperability in R","title":"Using FAIR Theory for Causal Inference","text":"Interoperability pertains ability use theory scientific workflows. X-interoperability refers ability use theory specific operations scientific workflows. go remainder tutorial, demonstrating FAIR tripartite model X-interoperable visualization R, selecting control variables, performing causal inference, et cetera. say: can directly ingest FAIR theory R, interact analysis environment use construct fully reproducible analysis workflows, including causal inference. First, let’s ingest theory R environment: , can plot model using tidySEM package:  can optionally specify layout graph, resembles model visualized Morris colleagues:  tidySEM vignette plotting structural equation models explains customize figure, ggplot object. Quiz  following describes property X-interoperability FAIR theory? can reused specific operation.can reused operation.can reused person.licenced reused.","code":"tripartite <- dagitty(paste(readLines(\"c:/theories/tripartite_downloaded/tripartite_model.txt\"), collapse = \"\\n\")) graph_sem(tripartite) lo <- get_layout(   \"\",   \"O\",  \"\",   \"\", \"\",   \"\",   \"PP\", \"\",   \"ER\",   \"A\",   \"\",   \"EC\", \"\",   \"\",   \"\",   \"PC\", \"\",   \"CC\", \"\",   \"\",   rows = 4 ) graph_sem(tripartite, layout = lo)"},{"path":"https://cjvanlissa.github.io/theorytools/articles/causal-inference.html","id":"simulating-data-from-the-fair-theory","dir":"Articles","previous_headings":"","what":"Simulating Data from the FAIR Theory","title":"Using FAIR Theory for Causal Inference","text":"Simulation studies allow us explore implications model assumptions, plan analyses data collection, conduct power analysis plan sample size, preregister fully reproducible analysis pipeline (Preregistration--Code, Peikert, Van Lissa, Brandmaier 2021; Van Lissa 2022). simple code snippet generate synthetic data using theorytools::simulate_data() function. function interprets DAG structural equation model, samples random values path coefficients (unless specific values provided), assumes normal residual variances. Note many functions simulating data exist, may better suited particular use cases. synthetic dataset consistent structure encoded Tripartite Model, though parameter values arbitrary. real research, might use prior studies expert knowledge set realistic parameter values. tutorial, select ad-hoc values, assign zero (0), small (.2), medium (.4) effect sizes paths DAG:","code":"set.seed(1) df_sim <- simulate_data(tripartite, n = 497) head(df_sim) #>            A         CC          EC          ER          O         PC #> 1  1.4283750  0.1952592  0.92442982 -0.02533034 -0.3079385 -0.3320551 #> 2  0.6110565  0.5038031 -0.43340243  0.11994203 -0.1300071 -0.4105931 #> 3  0.9664801 -0.2880780  0.16515985  1.19959014  0.4153041 -0.4792975 #> 4  0.4108811  1.0183695  0.03334491 -1.31108579  0.7340244 -0.9784317 #> 5 -0.5930765 -0.9278015  0.68502195 -0.40608709  0.4953758 -0.2662130 #> 6  2.7303903  0.6736708 -1.96050511  1.30038387 -1.3353841 -1.0096257 #>            PP #> 1 -0.09642845 #> 2 -0.15211457 #> 3 -0.10912407 #> 4  1.12574549 #> 5 -1.51551309 #> 6 -1.47788571 tripartite_coef <- dagitty('dag { O PP EC PC CC ER A  PC -> CC [beta=.4] PC -> EC [beta=.2] PC -> PP [beta=.2] PC -> O [beta=0]  O -> ER [beta=.2] PP -> ER [beta=0] EC -> ER [beta=.2]  ER -> A [beta=.4]  CC -> ER [beta=.4];  PP -> O [beta=0] EC -> O [beta=0] PP -> EC  [beta=.2] }') set.seed(51) df_sim <- simulateSEM(tripartite_coef, N = 497)"},{"path":"https://cjvanlissa.github.io/theorytools/articles/causal-inference.html","id":"selecting-control-variables","dir":"Articles","previous_headings":"","what":"Selecting Control Variables","title":"Using FAIR Theory for Causal Inference","text":"One advantage DAG ability identify variables controlled (e.g., avoid confounding) variables controlled (e.g., colliders). dagitty, can use function adjustmentSets() find minimal sufficient adjustment sets estimating specific causal effects. instance, let’s say want examine causal effect Observation Emotion Regulation. can run: DAG-based algorithm identifies sets variables sufficient block backdoor paths, given strong assumptions (Pearl 1995). result suggests enough control Child Characteristics, Emotional Climate, Parenting Practices wish obtain unbiased estimate effect Observation Emotion Regulation. Alternatively, can control Parent Characteristics, Emotional Climate, Parenting Practices. Quiz  estimating effect Observation Emotion Regulation, fine control Child Characteristics Parent Characteristics. TRUEFALSE","code":"adjustmentSets(tripartite, exposure=\"O\", outcome=\"ER\") #> { CC, EC, PP } #> { EC, PC, PP }"},{"path":"https://cjvanlissa.github.io/theorytools/articles/causal-inference.html","id":"basic-causal-inference","dir":"Articles","previous_headings":"","what":"Basic Causal Inference","title":"Using FAIR Theory for Causal Inference","text":"know variables control , can use standard regression estimate causal effect. Using regression assumes causal effects linear additive, normally distributed residuals predictors without measurement error. methods exist make assumptions. can use function select_controls() construct data.frame exposure, outcome, relevant control variables. facilitates conducting causal inference appropriate control variables, can just use model formula outcome ~ exposure obtain uncontrolled effect, outcome ~ . obtain causal estimate. Quiz  causal effect Observation Emotion Regulation? significant causal effect Observation Emotion Regulation. TRUEFALSE","code":"df_controls <- select_controls(tripartite, df_sim, exposure = \"O\", outcome = \"ER\") model_bivariate <- lm(ER ~ O, df_controls) model_causal <- lm(ER ~., df_controls) summary(model_bivariate) #>  #> Call: #> lm(formula = ER ~ O, data = df_controls) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -2.8773 -0.6705 -0.0366  0.7262  3.2154  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|) #> (Intercept) -0.02616    0.04608  -0.568    0.571 #> O            0.06788    0.04652   1.459    0.145 #>  #> Residual standard error: 1.023 on 495 degrees of freedom #> Multiple R-squared:  0.004283,   Adjusted R-squared:  0.002271  #> F-statistic: 2.129 on 1 and 495 DF,  p-value: 0.1452 summary(model_causal) #>  #> Call: #> lm(formula = ER ~ ., data = df_controls) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -2.5732 -0.5483  0.0839  0.6073  3.4954  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept) -0.03514    0.04053  -0.867  0.38633     #> O            0.13537    0.04140   3.270  0.00115 **  #> CC           0.46224    0.04085  11.315  < 2e-16 *** #> EC           0.19545    0.03996   4.891 1.36e-06 *** #> PP          -0.04527    0.04082  -1.109  0.26793     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.8965 on 492 degrees of freedom #> Multiple R-squared:  0.2397, Adjusted R-squared:  0.2335  #> F-statistic: 38.78 on 4 and 492 DF,  p-value: < 2.2e-16"},{"path":"https://cjvanlissa.github.io/theorytools/articles/causal-inference.html","id":"using-real-data","dir":"Articles","previous_headings":"","what":"Using Real Data","title":"Using FAIR Theory for Causal Inference","text":"working real data, causal inference quickly becomes complicated. Therefore, provide “real data” example , practice relevant skills. theorytools package includes dataset takes inspiration “Growing Australia - Longitudinal Study Australian Children” (LSAC, Family Studies 2020). LSAC dataset accessible explicit permission , synthetic dataset similar properties real data. Let’s access data:","code":"head(lsac) #>     warmth relationship_quality temperament_negreact emotion_regulation #> 1 3.500000             2.285714                 1.75                2.4 #> 2 5.000000             3.285714                 1.75                1.0 #> 3 5.000000             3.857143                 2.00                2.0 #> 4 3.333333             3.285714                 1.75                1.0 #> 5 4.333333             2.857143                 2.25                1.8 #> 6 2.833333                  NaN                 5.00                1.4 #>   social_functioning coping #> 1                3.0      2 #> 2                1.6      3 #> 3                1.8      5 #> 4                1.2      3 #> 5                1.2      4 #> 6                2.6      1"},{"path":"https://cjvanlissa.github.io/theorytools/articles/causal-inference.html","id":"mapping-theoretical-constructs-onto-measured-variables","dir":"Articles","previous_headings":"Using Real Data","what":"Mapping Theoretical Constructs onto Measured Variables","title":"Using FAIR Theory for Causal Inference","text":"Using real data, need find operationalizations theoretical constructs DAG, , need map theoretical constructs onto measured variables. inspect documentation data, can conclude likely mapping constructs variables : Let’s rename variables, data DAG consistent. also perform rudimentary imputation, missing data can cause problems later . Note abundant literature best practices handling missing data; , use single imputation pragmatic reasons. Note one variable missing: Observation (O). unfortunate, previous example used O exposure variable. remainder examples, use Parenting Practices exposure variable. Obtain adjustment set effect Parenting Practices Emotion Regulation: DAG implies conditional independencies: variables statistically independent one another, controlling specific adjustment set. kind assumption check, test variables dataset indeed show statistical independencies. data show dependencies DAG implies independence, can taken evidence veracity DAG. course, alternative explanations: operationalized construct, presence measurement error, sampling bias, et cetera. function localTests applies d-separation criterion determine conditional independencies implied DAG, performs tests . Different types tests available different types variables. continuous variables (), \"cis.loess\" method provides non-parametric conditional independence tests using bootstrapped loess regression. Let’s first conduct conditional independence tests dataset simulated DAG. ’re conducting lot significance tests, can control overall probability making Type error (.e., drawing false positive conclusions discrepancies DAG data). can use Bonferroni-corrected bootstrapped confidence intervals testing, demonstrated following code block: Now, let’s perform tests real data. missing variable, test complete set. can filter conditional independencies tested. Don’t forget use different Bonferroni correction resulting (smaller number ) tests! Quiz  can use Parenting Practices O adjustment set. TRUEFALSE causal effects can estimate using data? CC -> AER -> PCPP -> AAll ci_tests give us reasons doubt df_sim consistent DAG. TRUEFALSE ci_tests give us reasons doubt df_real consistent DAG. TRUEFALSE","code":"operationalizations <- c(PP = \"warmth\", EC = \"relationship_quality\", CC = \"temperament_negreact\", ER = \"emotion_regulation\", A = \"social_functioning\", PC = \"coping\") # Impute missing data df_real <- VIM::kNN(lsac, numFun = median) names(df_real) <- names(operationalizations)[match(operationalizations, names(df_real))] adjustmentSets(tripartite, exposure = \"EC\", outcome = \"ER\") #> { PC, PP } # Get all DAG-implied conditional independencies cis <- impliedConditionalIndependencies(tripartite) # Bonferroni-corrected confidence interval bonferroni <- 1-(.05/length(cis)) # Conduct the tests ci_tests <- localTests(tripartite, df_sim, type = \"cis.loess\", R = 1000, tests = cis, conf.level = bonferroni) # Print result, with added significance asterisks add_significance(ci_tests) #>                               estimate  std.error       0.25%      99.75% #> A _||_ CC | ER             -0.02488395 0.04541527 -0.14715226 0.108502878 #> A _||_ EC | ER             -0.08206144 0.04910397 -0.20560400 0.055630567 #> A _||_ O | ER               0.01604344 0.04103371 -0.09277371 0.135921735 #> A _||_ PC | CC, EC, O, PP  -0.06710313 0.04162413 -0.18500210 0.033920284 #> A _||_ PC | ER             -0.06037961 0.04378464 -0.17342936 0.056272447 #> A _||_ PP | ER             -0.01504872 0.04463377 -0.13707558 0.109638952 #> CC _||_ EC | PC            -0.06701484 0.04548868 -0.18696604 0.058277531 #> CC _||_ O | PC             -0.04608873 0.04135799 -0.15492342 0.067892851 #> CC _||_ PP | PC             0.03402876 0.04614528 -0.09232252 0.161732327 #> ER _||_ PC | CC, EC, O, PP -0.11134996 0.04751354 -0.23923411 0.009837374 #>                            significant #> A _||_ CC | ER                         #> A _||_ EC | ER                         #> A _||_ O | ER                          #> A _||_ PC | CC, EC, O, PP              #> A _||_ PC | ER                         #> A _||_ PP | ER                         #> CC _||_ EC | PC                        #> CC _||_ O | PC                         #> CC _||_ PP | PC                        #> ER _||_ PC | CC, EC, O, PP cis_real <- filter_conditional_independencies(cis, df_real) bonferroni <- 1-(.05/length(cis_real)) # Conduct the tests ci_tests <- localTests(tripartite, df_real, type = \"cis.loess\", R = 1000, tests = cis_real, conf.level = bonferroni) # Print result, with added significance asterisks add_significance(ci_tests) #>                    estimate  std.error 0.416666666666665% 99.5833333333333% #> A _||_ CC | ER   0.33415818 0.01156398          0.3050274        0.36573861 #> A _||_ EC | ER  -0.07461219 0.01175213         -0.1048497       -0.04367367 #> A _||_ PC | ER  -0.18556313 0.01142589         -0.2152855       -0.15789145 #> A _||_ PP | ER  -0.11868779 0.01128070         -0.1465077       -0.09036928 #> CC _||_ EC | PC -0.07078118 0.01182194         -0.1023458       -0.03836728 #> CC _||_ PP | PC -0.19258437 0.01229991         -0.2222188       -0.15670884 #>                 significant #> A _||_ CC | ER            * #> A _||_ EC | ER            * #> A _||_ PC | ER            * #> A _||_ PP | ER            * #> CC _||_ EC | PC           * #> CC _||_ PP | PC           *"},{"path":[]},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"before-starting-this-tutorial","dir":"Articles","previous_headings":"","what":"Before Starting This Tutorial","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"must Set computer WORCS Running worcs::check_worcs_installation() return green checkmarks","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"learning-goals","dir":"Articles","previous_headings":"","what":"Learning Goals","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"tutorial, learn : Create reproducible research project using WORCS. Import “FAIR theory”, specified augmented DAG. Create computational simulation study based FAIR theory. Add targets simulation study reduce redundant compute Add integration testing study ensure functions work intended","code":""},{"path":[]},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"create-a-new-worcs-project","dir":"Articles","previous_headings":"Setting up a Reproducible Project with WORCS","what":"1. Create a new WORCS Project","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"WORCS helps automate reproducible workflows setting version control, metadata, licenses, . Open RStudio. Choose directory name, e.g., \"fair_theory_simulation\". Optionally, can create GitHub repository. GitHub integration set , required specify GitHub remote repository name. Keep Manuscript template set “GitHub document” Keep Preregistration template set “None” Keep License set “cc0” CC-0 copyright waiver Select “Use renv” De-select “Use targets”: use targets next chapter, ’ll add support manually didactic purposes. ’re familiar targets workflow, feel free add automatically creating next project. Select “Open new session” Click Create Project. WORCS now set project implements best practices reproducibility. new Rstudio instance open automatically. working next sections, add code chunks \"manuscript.Rmd\" file except code labeled Interactive:. Code labeled Interactive: run , Console window. code can inserted code chunks \"manuscript.Rmd\" file; knit regularly verify everything runs expected. mean run R code interactively?","code":"webexercises::mcq(sample(c(answer = \"Executing code immediately in an R session that a human user is interacting with.\", \"Having one function call another function; these functions are said to be 'interacting'\", \"Evaluating code by placing it in an Rmarkdown document, and knitting that document.\"))) ## [1] \"<select class='webex-select'><option value='blank'><\/option><option value='answer'>Executing code immediately in an R session that a human user is interacting with.<\/option><option value=''>Evaluating code by placing it in an Rmarkdown document, and knitting that document.<\/option><option value=''>Having one function call another function; these functions are said to be 'interacting'<\/option><\/select>\""},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"download-a-fair-theory","dir":"Articles","previous_headings":"Setting up a Reproducible Project with WORCS","what":"2. Download a FAIR Theory","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"Interactive: ’ll need install packages run tutorial. Run code: \"manuscript.Rmd\" file, add following lines setup chunk: use FAIR version Self-Determination Theory (SDT). vignette Formalizing Self-Determination Theory describes FAIR theory created based original Self-Determination Theory (Deci Ryan 2012). specified Directed Acyclic Graph, DAG: diagram specifies causal relations proposed theory. diagrams can used derive hypotheses, select control variables causal inference, conduct simulation studies (tutorial). Interactive: Run code download existing FAIR theory, stored Zenodo. create new subfolder called \"theory/\" files, theory repository README LICENSE files; don’t want overwrite files WORCS repository. Optionally, can look archived version opening URL https://doi.org/10.5281/zenodo.15648655. theory includes README file, describing contents files, LICENSE describing theory can reused, file called sdt.txt containing DAG, definitions.csv, containing construct definitions. Note definitions require specification; explained Vignette formalizing SDT), book chapter describing theory explicitly define constructs involved. FAIR theory downloaded separate theory/ subfolder?","code":"install.packages(\"theorytools\", prompt = FALSE) install.packages(\"dagitty\", prompt = FALSE) install.packages(\"tidySEM\", prompt = FALSE) library(theorytools) library(dagitty) library(tidySEM) theorytools::download_theory(\"10.5281/zenodo.15648655\", path = \"theory\") webexercises::mcq(sample(c(answer = \"To prevent overwriting the WORCS project's README and LICENSE files\", \"To avoid downloading unnecessary files\", \"Because theorytools only works inside a 'theory/' directory\", \"Because dagitty requires theory files to be placed in a specific folder\"))) ## [1] \"<select class='webex-select'><option value='blank'><\/option><option value=''>Because theorytools only works inside a 'theory/' directory<\/option><option value='answer'>To prevent overwriting the WORCS project's README and LICENSE files<\/option><option value=''>To avoid downloading unnecessary files<\/option><option value=''>Because dagitty requires theory files to be placed in a specific folder<\/option><\/select>\""},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"load-the-fair-theory","dir":"Articles","previous_headings":"Setting up a Reproducible Project with WORCS","what":"3. Load the FAIR Theory","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"FAIR theory augmented DAG, can read using dagitty package. vignette Specifying Augmented Directed Acyclic Graphs describes augmented DAGs . DAGs particularly useful computational social science studies, theorytools package contains methods convert augmented DAGs generative models. Now, let’s load augmented DAG. Note: running code code chunk Rmarkdown file, must use file path ../theory/sdt.txt go back parent directory, manuscript theory different subdirectories. run interactively instead, already inside parent directory, can use path theory/sdt.txt. , can plot model using tidySEM package. Get basic plot running graph_sem(sdt):  According DAG, causes wellbeing?","code":"sdt <- dagitty::dagitty(paste(readLines(\"../theory/sdt.txt\"), collapse = \"\\n\")) tidySEM::graph_sem(sdt) webexercises::mcq(sample(c(answer = \"integration, intrinsic_motivation, needs\", \"integration, intrinsic_motivation\", \"needs, intrinsic_ _motivation\"))) ## [1] \"<select class='webex-select'><option value='blank'><\/option><option value=''>needs, intrinsic_ _motivation<\/option><option value='answer'>integration, intrinsic_motivation, needs<\/option><option value=''>integration, intrinsic_motivation<\/option><\/select>\""},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"creating-a-computational-model","dir":"Articles","previous_headings":"Setting up a Reproducible Project with WORCS","what":"4. Creating a Computational Model","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"Computational simulation studies allow us generate analyze simulated datasets, example : Explore -scenarios Test implications model assumptions Plan analyses data collection Conduct power analysis plan sample size Preregister fully reproducible analysis pipeline (Preregistration--Code, Peikert, Van Lissa, Brandmaier 2021; Van Lissa 2022). simple code snippet generate synthetic data using theorytools::simulate_data() function. function samples random values exogenous variables computes endogenous variables functions predictors (linear functions, default). default, regression coefficients randomly sampled range [-0.6, +0.6] unless specific values provided user. might use prior studies expert knowledge set realistic parameter values, use conventional values null (0), small (.2), medium (.4) effect sizes. default, normal distributions assumed exogenous variables residual error, unless distributions specified. Note many functions simulating data exist, may better suited particular use cases. tutorial Specifying Augmented DAGS contains information user-defined functional forms (error) distributions. synthetic dataset consistent structure encoded FAIR SDT, though parameter values arbitrary. following reason use computational simulation studies?","code":"set.seed(1) theorytools::simulate_data(sdt, n = 5) webexercises::mcq(sample(c(answer = \"Fitting a model to real-world data\", \"Exploring what-if scenarios\", \"Conducting power analysis\", \"Preregistering a reproducible analysis pipeline\"))) ## [1] \"<select class='webex-select'><option value='blank'><\/option><option value=''>Exploring what-if scenarios<\/option><option value='answer'>Fitting a model to real-world data<\/option><option value=''>Preregistering a reproducible analysis pipeline<\/option><option value=''>Conducting power analysis<\/option><\/select>\""},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"simplifying-the-model","dir":"Articles","previous_headings":"Setting up a Reproducible Project with WORCS > 4. Creating a Computational Model","what":"Simplifying the Model","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"Suppose interested studying effect intrinsic motivation well-. Even research grounded SDT, need entire theory hypothesize specific relationship. can use DAG derive restricted version theory includes variables might confound relationship interest intrinsic motivation well-: can now generate synthetic dataset based simplified DAG:","code":"sdt_pruned <- theorytools:::prune_dag(sdt,                                       exposure = \"intrinsic_motivation\",                                       outcome = \"wellbeing\") sdt_pruned ## dag { ## intrinsic_motivation ## needs ## wellbeing ## intrinsic_motivation -> wellbeing ## needs -> intrinsic_motivation ## needs -> wellbeing ## } set.seed(1) df <- theorytools::simulate_data(sdt_pruned, n = 100) head(df)"},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"analyze-the-simulated-data","dir":"Articles","previous_headings":"Setting up a Reproducible Project with WORCS","what":"5. Analyze the Simulated Data","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"goal conduct computational study, can manipulate aspect data simulation procedure. manipulations independent variables computational study. can apply kind analysis simulated data obtain outcome (dependent variable) computational study. One basic types computational simulation studies power analysis, manipulate true effect size parameter (independent variable: effect size) calculate whether observe significant result test parameter simulated data (dependent variable: significance). analysis function case simple significance test parameter interest. First, conduct bivariate linear regression (DAG indicated need control effect needs): , outcome interest significance effect intrinsic_motivation. can extract p-value follows, compare significance level α<.05\\alpha < .05 get binary result (significant: TRUE FALSE): Run code , answer true false: one dataset, result significant.","code":"res <- lm(wellbeing ~ intrinsic_motivation + needs, data = df) summary(res) ##  ## Call: ## lm(formula = wellbeing ~ intrinsic_motivation + needs, data = df) ##  ## Residuals: ##      Min       1Q   Median       3Q      Max  ## -2.93688 -0.87862 -0.03086  0.74147  2.56125  ##  ## Coefficients: ##                      Estimate Std. Error t value Pr(>|t|)     ## (Intercept)          -0.02492    0.11579  -0.215 0.830069     ## intrinsic_motivation  0.44496    0.11522   3.862 0.000203 *** ## needs                -0.30228    0.11815  -2.558 0.012061 *   ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Residual standard error: 1.126 on 97 degrees of freedom ## Multiple R-squared:  0.1839, Adjusted R-squared:  0.1671  ## F-statistic: 10.93 on 2 and 97 DF,  p-value: 5.231e-05 sum_res <- summary(res) sum_res$coefficients[\"intrinsic_motivation\", \"Pr(>|t|)\"] < .05 webexercises::torf(TRUE) ## [1] \"<select class='webex-select'><option value='blank'><\/option><option value='answer'>TRUE<\/option><option value=''>FALSE<\/option><\/select>\""},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"using-worcs-with-targets-sustainable-reproducibility","dir":"Articles","previous_headings":"","what":"Using worcs with targets: Sustainable Reproducibility","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"One main tenets open reproducible science ability re-run analyses raw data published output, ensure results still valid. However, computationally intensive projects, re-running unchanged code repeatedly can redundant, slow, wasteful. targets package reduces unnecessary compute breaking analysis pipeline steps explicitly reference one another, step re-computed either step changed, inputs changed. Reducing unnecessary computation speeds analysis process reduces carbon footprint analyses (Gupta et al. 2021). combining worcs targets, get best worlds: worcs used create fully reproducible research archive; targets ensures redundant steps reproducible analysis pipeline unnecessarily re-computed.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"add-targets-to-the-worcs-project","dir":"Articles","previous_headings":"Using worcs with targets: Sustainable Reproducibility","what":"6. Add targets to the WORCS Project","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"Interactive: Let’s install packages required next section: Interactive: , add targets integration worcs project running: Note status messages. newly created _targets.R file specifies steps reproducible workflow. newly created \"./R/\" directory contain functions used workflow.","code":"install.packages(\"targets\", prompt = FALSE) install.packages(\"tarchetypes\", prompt = FALSE) worcs::add_targets()"},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"try-running-the-pipeline","dir":"Articles","previous_headings":"Using worcs with targets: Sustainable Reproducibility","what":"7. Try Running the Pipeline","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"Open file _targets.R. Note default pipeline (look something like code ) consists placeholder steps: Create data Run model Render manuscript.Rmd Interactive: can run pipeline executing command targets::tar_make().","code":"list(   tar_target(     name = data,     command = tibble(x = rnorm(100), y = rnorm(100))   ),   tar_target(     name = model,     command = coefficients(lm(y ~ x, data = data))   ),   tarchetypes::tar_render(manuscript, \"manuscript/manuscript.Rmd\") )"},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"set-a-seed","dir":"Articles","previous_headings":"Using worcs with targets: Sustainable Reproducibility > 7. Try Running the Pipeline","what":"Set a Seed","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"Computational simulation studies typically rely random number generation repeatedly simulate scenario variability. dependency random numbers makes results non-reproducible (random numbers different upon repeated evaluation). Fortunately, true random numbers rarely used: typically use sequence pseudo random numbers. make randomness reproducible, can set “seed” random number generator. Setting seed essentially jumps sequence pseudo-random numbers point time, get “random” numbers . set seed, add command set.seed(1) targets pipeline. can use number instead 1, lead different results.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"debugging","dir":"Articles","previous_headings":"Using worcs with targets: Sustainable Reproducibility > 7. Try Running the Pipeline","what":"Debugging","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"Running targets::tar_make() might fail; observed two modes failure: find file ../theory/sdt.txt; changing theory/sdt.txt seems work. Perhaps targets::tar_make() evaluates code chunks parent directory? targets::tar_make() fails first time, succeeds re-running second time.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"create-your-own-functions","dir":"Articles","previous_headings":"Using worcs with targets: Sustainable Reproducibility","what":"8. Create Your Own Functions","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"Now, let’s create functions steps need computational simulation study (power analysis).","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"function-to-generate-data","dir":"Articles","previous_headings":"Using worcs with targets: Sustainable Reproducibility > 8. Create Your Own Functions","what":"Function to Generate Data","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"First, need function generate synthetic data, allows us manipulate true effect size. simulate_data() function used previously create single synthetic dataset can also generate script synthetic data generation: Let’s write script new file ./R/, edit . Interactive: Run following code: Open file R/generate_data.R, edit follows (way please): Wrap code fuction() call arguments beta, n Comment random seed, run different Comment n <- 100 n controlled via function arguments Replace fixed effect size intrinsic_motivation argument beta, effect size controlled via function arguments","code":"theorytools::simulate_data(sdt_pruned, n = 100, run = FALSE) ##  [1] \"# Set random seed\"                                                      ##  [2] \"set.seed(644938424)\"                                                    ##  [3] \"# Set simulation parameters\"                                            ##  [4] \"n <- 100\"                                                               ##  [5] \"# Simulate exogenous nodes\"                                             ##  [6] \"needs <- rnorm(n = n)\"                                                  ##  [7] \"# Simulate endogenous nodes\"                                            ##  [8] \"intrinsic_motivation <- 0.16 * needs + rnorm(n = n)\"                    ##  [9] \"wellbeing <- 0.21 * intrinsic_motivation - 0.21 * needs + rnorm(n = n)\" ## [10] \"df <- data.frame(\"                                                      ## [11] \"intrinsic_motivation = intrinsic_motivation,\"                           ## [12] \"needs = needs,\"                                                         ## [13] \"wellbeing = wellbeing\"                                                  ## [14] \")\" writeLines(   theorytools::simulate_data(sdt_pruned, n = 100, run = FALSE),   \"R/generate_data.R\" ) generate_data <- function(beta, n){ # Set random seed # set.seed(442008606) # Set simulation parameters # n <- 100 # Simulate exogenous nodes needs <- rnorm(n = n) # Simulate endogenous nodes intrinsic_motivation <- -(0.19 * needs) + rnorm(n = n) wellbeing <- beta * intrinsic_motivation - 0.42 * needs + rnorm(n = n) df <- data.frame( intrinsic_motivation = intrinsic_motivation, needs = needs, wellbeing = wellbeing ) return(df) }"},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"optional-the-effect-of-needs","dir":"Articles","previous_headings":"Using worcs with targets: Sustainable Reproducibility > 8. Create Your Own Functions","what":"Optional: The Effect of Needs","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"Note effect needs intrinsic_motivation wellbeing hard-coded code snippet . possible draw random value effects time. , (example) replace fixed values runif(1, min = -.4, max = .4).","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"function-to-analyze-data","dir":"Articles","previous_headings":"Using worcs with targets: Sustainable Reproducibility > 8. Create Your Own Functions","what":"Function to Analyze Data","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"Now, create another file called analyze_data.R contain function perform analysis procedure defined step 5:","code":"analyze_data <- function(df){ # Conduct linear regression res <- lm(wellbeing ~ intrinsic_motivation + needs, data = df) # Obtain a model summary sum_res <- summary(res) # Compare p-value of our coefficient of interest to the significance level, .05 sum_res$coefficients[\"intrinsic_motivation\", \"Pr(>|t|)\"] < .05 }"},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"function-to-conduct-the-study","dir":"Articles","previous_headings":"Using worcs with targets: Sustainable Reproducibility > 8. Create Your Own Functions","what":"Function to Conduct the Study","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"also need function conduct computational simulation study . Create file called perform_study.R, containing function like (feel free develop ):","code":"perform_study <- function(study_design, reps = 100){   # For each row of the study design, execute a function   pwr <- apply(study_design, 1, function(thisrow){     # Replicate the row of the study design reps times     out <- replicate(n = reps, expr = {       # Simulate data with the beta and n from thisrow       df <- with(as.list(thisrow), generate_data(beta = beta, n = n))       # Analyze those data       analyze_data(df)     })     # Calculate the proportion of significant results using mean()     mean(out)   })   # Make a data frame containing the study design and study results (pwr)   data.frame(study_design, power = pwr) }"},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"create-your-own-pipeline","dir":"Articles","previous_headings":"Using worcs with targets: Sustainable Reproducibility","what":"9. Create Your Own Pipeline","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"file _targets.R, can now define pipeline computational simulation study. step pipeline, define tar_target(), naming output name. goal create list looks something like :","code":"list(   tar_target(     name = study_design,     command = ...   ),   tar_target(     name = study_results,     command = ...   ),   tarchetypes::tar_render(manuscript, \"manuscript/manuscript.Rmd\") )"},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"create-study-design","dir":"Articles","previous_headings":"Using worcs with targets: Sustainable Reproducibility > 9. Create Your Own Pipeline","what":"Create Study Design","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"power analysis, can manipulate true effect size sample size. Let’s say want design study true effect size β∈[.1,.2,.4]\\beta \\[.1, .2, .4] sample size n∈[50,100,200]n \\[50, 100, 200] (convenience’s sake, omit analysis false-positive results β=0\\beta = 0 now). can use R-function expand.grid() create possible combinations: Add pipeline follows: Now, add another target conduct study, based study_design. Explicitly referencing object name ensure code re-run study_design changes (verify ).","code":"expand.grid(   beta = c(.1, .2, .4),   n = c(50, 100, 200) ) ##   beta   n ## 1  0.1  50 ## 2  0.2  50 ## 3  0.4  50 ## 4  0.1 100 ## 5  0.2 100 ## 6  0.4 100 ## 7  0.1 200 ## 8  0.2 200 ## 9  0.4 200 tar_target(     name = study_design,     command = expand.grid(       beta = c(.1, .2, .4),       n = c(50, 100, 200)     )   ) tar_target(     name = study_results,     command = perform_study(study_design = study_design, reps = 100)   )"},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"edit-manuscript-rmd","dir":"Articles","previous_headings":"Using worcs with targets: Sustainable Reproducibility","what":"10. Edit manuscript.Rmd","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"Now, open manuscript.Rmd edit load study_results tabulate plot . load study results, replace default line tar_load(model) (mock pipeline created earlier) tar_load(study_results). Using tar_load() inside manuscript.Rmd makes latter dependent former. Thus, study_results changes, manuscript automatically re-run. Interactive: verify interdependencies pipeline steps properly tracked, can run:  Add following code manuscript tabulate results: alternatively, add following code plot study results (requires running install.packages(\"ggplot2\", prompt = FALSE)).","code":"install.packages(\"visNetwork\", prompt = FALSE) targets::tar_visnetwork() knitr::kable(study_results, digits = 2) library(ggplot2) df_plot <- study_results df_plot$beta <- ordered(df_plot$beta) ggplot(df_plot, aes(x = n, y = power, color = beta, shape = beta)) +   geom_point() +   geom_line() +   theme_bw()"},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"run-the-pipeline","dir":"Articles","previous_headings":"Using worcs with targets: Sustainable Reproducibility","what":"11. Run the Pipeline","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"Interactive: successful, able run pipeline calling targets::tar_make().","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"add-endpoints","dir":"Articles","previous_headings":"Using worcs with targets: Sustainable Reproducibility","what":"12. Add Endpoints","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"worcs package allows specify endpoints analysis; makes possible check whether analysis results identical upon repeated evaluation. analysis /fully deterministic, random numbers controlled set.seed() ensure identical results upon repeated evaluation, ’s possible specify entire output document (e.g., manuscript.html) endpoint. Alternatively, document depend non-deterministically random numbers (e.g., plot results random jitter), exactly reproduced. case, can either remove non-deterministic sources randomness, simply track deterministic intermediate outputs endpoints. example, write analysis results .csv file, track endpoint. can add endpoint calling worcs::add_endpoint(\"manuscript/manuscript.html\"). endpoint intentionally changed (e.g., updated analysis code), can update record calling worcs::snapshot_endpoints(). can call worcs::reproduce(), (project targets) calls tar_make() calls worcs::check_endpoints() verify endpoints reproduce re-running analysis. mindful fact targets re-run pipeline steps step, inputs step, changed. means might look like code reproduces upon repeat evaluation - code actually re-evaluated, targets retrieved results cache. properly evaluate whether code reproduces, must first destroy cache pipeline results running worcs::reproduce(). causes targets re-run every step pipeline. might look like:","code":"# Snapshot the current state of the endpoints worcs::snapshot_endpoints() # Destroy the cache of targets results targets::tar_destroy() # worcs::reproduce() calls targets::tar_make(), then worcs::check_endpoints() worcs::reproduce()"},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"optional-use-parallel-computation","dir":"Articles","previous_headings":"","what":"Optional: Use Parallel Computation","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"Computational studies, like power analyses via Monte Carlo simulation, often require repeating computations many times, can time-consuming. Modern computers (CPUs) usually multiple “cores”; default, program like Rstudio uses one core - ’s possible assign task multiple cores. Parallel computing practice distributing computational task across multiple CPU cores, significantly speeding execution. section, ’ll learn parallelize simulation study using future package. package simple interface can implemented perform_study() function minimal code changes.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"install-and-load-required-packages","dir":"Articles","previous_headings":"Optional: Use Parallel Computation","what":"1. Install and Load Required Packages","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"various ways implement parallel computing, methods specific different operating systems. method works (least) Windows. Interactive: First, install required packages:","code":"install.packages(\"future\", prompt = FALSE)"},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"adding-paralellization-to-perform_study","dir":"Articles","previous_headings":"Optional: Use Parallel Computation","what":"2. Adding Paralellization to perform_study()","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"Paralellization R requires registering parallel backend: essentially, starting R-session cores want use, loading required functions packages . cores access main R-session using interactively; see variables functions loaded. register parallel backend, can add following code perform_study(): Instead hard-coding number workers (cores) 4L (integer 4), choose number based computer’s actual number cores. can determine number cores running parallelly::availableCores(). can use cores parallel computing, people often use one two fewer can keep using computer simulation running. , adapt code follows: Note Mac Linux, might able use efficient backend ‘forking’ processes. , use plan(multicore) instead plan(multisession). package future.apply contains parallel equivalents base R functions like lapply(), sapply(), importantly, replicate(). paralellize inner loop simulation, can use: argument future.seed ensures random seeds properly handled results replicable. information seeds parallel computation, see blog post.","code":"library(future) plan(multisession, workers = 4L) library(future) plan(multisession, workers = parallelly::availableCores()-2L) future.apply::future_replicate(n = reps, expr = {       df <- with(as.list(thisrow), generate_data(beta = beta, n = n))       analyze_data(df)     },     future.seed = TRUE)"},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"what-to-paralellize","dir":"Articles","previous_headings":"Optional: Use Parallel Computation > 2. Adding Paralellization to perform_study()","what":"What to Paralellize?","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"Computational simulation studies often consist loops-within-loops. Deciding loop paralellize bit art form, area specialization. Considerations weigh decision : overhead (terms processing time) set parallel backend? bottleneck: simulation fill working memory, max processor? can use code profiling assess CPU memory bottlenecks, beyond scope present tutorial. case, paralellize across 9 conditions study, across 100 replications conditions. chose paralellize across 9 study conditions, core execute one condition 100 times. Compare function perform_study() without paralellization:","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"without-paralellization","dir":"Articles","previous_headings":"Optional: Use Parallel Computation > 2. Adding Paralellization to perform_study() > What to Paralellize?","what":"Without Paralellization","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"","code":"perform_study <- function(study_design, reps = 100){   # For each row of the study design, execute a function   pwr <- apply(study_design, 1, function(thisrow){     # Replicate the row of the study design reps times     out <- replicate(n = reps, expr = {       # Simulate data with the beta and n from thisrow       df <- with(as.list(thisrow), generate_data(beta = beta, n = n))       # Analyze those data       analyze_data(df)     })     # Calculate the proportion of significant results using mean()     mean(out)   })   # Make a data frame containing the study design and study results (pwr)   data.frame(study_design, power = pwr) }"},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"with-paralellization","dir":"Articles","previous_headings":"Optional: Use Parallel Computation > 2. Adding Paralellization to perform_study() > What to Paralellize?","what":"With Paralellization","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"","code":"perform_study <- function(study_design, reps = 100){   library(future)   # Sets up clusters from number of cores   plan(multisession, workers = parallelly::availableCores()-2L)   pwr <- apply(study_design, 1, function(thisrow){     # Replicate the row of the study design reps times     out <- future.apply::future_replicate(n = reps, expr = {       # Simulate data with the beta and n from thisrow       df <- with(as.list(thisrow), generate_data(beta = beta, n = n))       # Analyze those data       analyze_data(df)     },     future.seed = TRUE)     # Calculate the proportion of significant results using mean()     mean(out)   })   data.frame(study_design, power = pwr) }"},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"re-run-the-pipeline","dir":"Articles","previous_headings":"Optional: Use Parallel Computation > 2. Adding Paralellization to perform_study()","what":"3. Re-run the Pipeline","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"Now rerun simulation : notice speedup? Probably , overhead associated setting parallel back-end outweighs time saved paralellization. running many repetitions conducting large computational simulation studies, time saved. can benchmark code estimate much time saved (beyond scope present tutorial).","code":"targets::tar_make()"},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"optional-add-integration-tests","dir":"Articles","previous_headings":"","what":"Optional: Add Integration Tests","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"Integration testing procedure used software development ensure code works expected. WORCS project, using integration tests increases scientific rigor helps ensure reproducibility. section explains bare basics integration testing reproducible research workflows; see R Packages book detail.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"why-write-tests","dir":"Articles","previous_headings":"Optional: Add Integration Tests","what":"Why Write Tests?","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"probably already test functions informally - write function, run console, see output looks good. better nothing - fool-proof? remember functions looked good 6 months? someone changes part code? functions used different way expected? Integration tests: Run automatically consistently. Help catch bugs. Provide documentation expected behavior. Encourage modular, testable code.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"when-to-test","dir":"Articles","previous_headings":"Optional: Add Integration Tests","what":"When to Test?","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"write new function. fixing bug (add test catch next time). sharing, submitting, publishing analysis.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"set-up-testthat","dir":"Articles","previous_headings":"Optional: Add Integration Tests","what":"1. Set Up testthat","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"Interactive: WORCS project, run following code: creates tests/testthat/ folder hold tests. Note two suggestions printed console: Run usethis::use_test() initialize basic test file open editing. Run worcs::github_action_testthat() add GitHub action evaluates integration tests.","code":"worcs::add_testthat()"},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"write-a-simple-test","dir":"Articles","previous_headings":"Optional: Add Integration Tests","what":"2. Write a Simple Test","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"Let’s prepare file test behavior function generate_data() running usethis::use_test(name = \"generate_data\"). default, test file look like , testing common sense math: test file contains: function call test_that() short description, case \"multiplication works\". One expectations evaluated, like expect_equal() example . Test files’ names must start test-, must saved tests/testthat/.","code":"test_that(\"multiplication works\", {   expect_equal(2 * 2, 4) })"},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"run-tests","dir":"Articles","previous_headings":"Optional: Add Integration Tests","what":"3. Run Tests","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"console script, can run: , test single file: output tell tests passed failed, failed.","code":"worcs::test_worcs() testthat::test_file(\"tests/testthat/test-generate_data.R\")"},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"customize-your-test","dir":"Articles","previous_headings":"Optional: Add Integration Tests","what":"4. Customize Your Test","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"want test generate_data()? ’s , consider testing assumptions make function, example: generates data.frame columns numeric number rows corresponds n number columns corresponds number variables DAG (tested ) high sample size n, regression coefficient intrinsic_motivation -> wellbeing approaches beta within certain tolerance assumptions look like tested? example, like: Copy-paste tests, write . Note , instead grouping tests, also break separate test_that() commands: main advantage style output testthat::test_dir() documented fine-grained level.","code":"test_that(\"generate_data works\", {   # Run generate_data()   df <- generate_data(.4, 100)   # It generates a `data.frame`   expect_s3_class(df, \"data.frame\")   # All columns are `numeric`   expect_true(all(sapply(df, inherits, what = \"numeric\")))   # The number of rows corresponds to `n`   expect_true(nrow(df) == 100)   # At high n, the regression coefficient approaches beta within tolerance   set.seed(1)   df <- generate_data(.4, 100000)   res <- lm(wellbeing ~ intrinsic_motivation + needs, data = df)   expect_equivalent(res$coefficients[2], .4, tolerance = .01) }) test_that(\"generate_data generates a data.frame\", {   # Run generate_data()   df <- generate_data(.4, 100)   # It generates a `data.frame`   expect_s3_class(df, \"data.frame\") })  test_that(\"generate_data returns all numeric columns\", {   df <- generate_data(.4, 100)   expect_true(all(sapply(df, inherits, what = \"numeric\"))) })"},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"run-your-tests-online","dir":"Articles","previous_headings":"Optional: Add Integration Tests","what":"5. Run your Tests Online","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"development platform ‘GitHub’ allows run code cloud (= servers). useful checking worcs project reproduces different system , also, run integration tests different system. avoids famous meme: GitHub Actions automation tool offered GitHub, allows developers run workflows directly repositories. using GitHub Actions, can automate processes continuous integration, continuous deployment, testing, code reviews. GitHub Actions triggered events - example, pushing code updates GitHub. Interactive: Let’s set GitHub action run integration tests: Interactive: virtual computer environment GitHub actions attempt recreate local environment based renv dependency manager. ensure renv records date, run code . important always snapshot dependencies reproducing analyses another system; run renv::snapshot() publishing code, triggering GitHub action, sharing code collaborator, et cetera. Interactive: Now, push code GitHub. Among files updated instructions GitHub actions .github/ folder, updated renv.lock file. Since GitHub action triggered pushing code GitHub, now navigate GitHub repository. don’t remember GitHub URL, run: see action running. good, show green dot (red errors). Integration testing gives peace mind - know code works expected, via GitHub actions, can show world .","code":"It works on my machine ¯\\_(ツ)_/¯ # Add the appropriate GitHub action: worcs::github_action_testthat() renv::snapshot() worcs::git_update(\"add testthat\") utils::browseURL(gsub(\".git\", \"/actions\", gert::git_remote_list()$url, fixed = TRUE))"},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"reproducing-your-analysis-online","dir":"Articles","previous_headings":"Optional: Add Integration Tests","what":"6. Reproducing your Analysis Online","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"worcs package also includes functionality reproduce entire analysis online via GitHub actions. However, running full simulation study probably fair use GitHub’s servers, might raise eyebrows. , smaller scale studies, vignette endpoints explains create GitHub action reproduce analyses cloud.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/computational_social_science.html","id":"additional-resources","dir":"Articles","previous_headings":"","what":"Additional Resources","title":"Conducting Theory-Based Reproducible Simulation Studies","text":"Using targets Reduce Redundant Computations WORCS documentation theorytools documentation FAIR Principles TOP Guidelines Paralellizing Code","code":""},{"path":[]},{"path":"https://cjvanlissa.github.io/theorytools/articles/dunning-kruger.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"FAIRifying the Dunning-Kruger Effect","text":"example, implement Dunning-Kruger (DK) effect, following formalization Feld, Sauermann, De Grip (2017). DK effect defined follows: “low performers vastly overestimate performance high performers accurately assess performance”. paper Feld colleagues restates DK effect terms skill overconfidence show measurement error can cause significant bias relationship performance overestimation. Statistical methods can used correct bias also discussed. Since theory contains definitions abstract concepts, relationships concepts, mathematical derivations well commonly used statistical models experimental paradigms, serves nice illustration formalize FAIRify different aspects.1","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/dunning-kruger.html","id":"learning-goals","dir":"Articles","previous_headings":"0.1 Introduction","what":"Learning Goals","title":"FAIRifying the Dunning-Kruger Effect","text":"completed tutorial, know : Implement theory consisting multiple aspects can represented format Learn FAIRify equations / proofs","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/dunning-kruger.html","id":"implement-the-theory","dir":"Articles","previous_headings":"","what":"1. Implement the Theory","title":"FAIRifying the Dunning-Kruger Effect","text":"Begin creating empty folder hold files associated theory - folder become theory archive. example, create folder: begin implementing theory; far greatest challenge tutorial.","code":"dir.create(\"dunning_kruger\") setwd(\"dunning_kruger\")"},{"path":"https://cjvanlissa.github.io/theorytools/articles/dunning-kruger.html","id":"definitions","dir":"Articles","previous_headings":"1 1. Implement the Theory","what":"Definitions","title":"FAIRifying the Dunning-Kruger Effect","text":"Let’s start collecting definitions theory makes use : performance test score performance estimation difference expected actual test score skill ability perform well given test overconfidence difference self-assessed actual skill measurement error luck test Since verbal definitions, can track markdown file:","code":"definitions <-  \" ## Definitions  - **performance** as a test score - **performance estimation** as the difference between the expected and the actual test score - **skill** as the ability to perform well on a given test - **overconfidence** as the difference between self-assessed and actual skill - **measurement error** as luck on a test \"  cat(definitions, file=\"definitions.md\")"},{"path":"https://cjvanlissa.github.io/theorytools/articles/dunning-kruger.html","id":"relationships","dir":"Articles","previous_headings":"1 1. Implement the Theory","what":"Relationships","title":"FAIRifying the Dunning-Kruger Effect","text":"can visualize originally proposed relationships concepts graph: well reformulation Feld, Sauermann, De Grip (2017): \\(-\\) signifying negative association, \\(\\simeq\\) signifying “measured ” \\(:=\\) signifying “defined ”. FAIRify graph, can use graph specification library igraph (Csárdi et al. 2025): can visualize graph  Finally, save graph standardized format GraphML:","code":"library(igraph, warn.conflicts=FALSE)  g <- graph_from_literal(     skill -- overconfidence,     skill -- performance,     overconfidence -- overestimation,     performance -- overestimation,     \"skill + error\" -- \"overconfidence - error\",     \"skill + error\" -- performance,     \"expected performance - performance\" -- overestimation,     \"expected performance - performance\" -- \"overconfidence - error\" )  E(g)$relationship <- c(  \"negative association\",  \"~\",  \"~\",  \"negative association\",  \":=\",  \":=\",  \"negative association\",  \"= (Theorem 1)\" ) plot(   g,   vertex.size = 20,   vertex.color = \"white\",   edge.label = E(g)$relationship, ) write_graph(   g,   \"relationship_graph.txt\",   format = \"graphml\" )"},{"path":[]},{"path":"https://cjvanlissa.github.io/theorytools/articles/dunning-kruger.html","id":"definitions-1","dir":"Articles","previous_headings":"1 1. Implement the Theory > 1.3 Mathematical formulation","what":"Definitions","title":"FAIRifying the Dunning-Kruger Effect","text":"define random variables \\(s^*\\) denoting skill \\(\\varepsilon\\) denoting measurement error, \\(\\mathbb{E}[\\varepsilon] = 0\\), \\(\\varepsilon\\) independent random variables included model \\(s^*_s\\) denoting self-assessed skill performance \\(p\\) \\[\\begin{equation}   \\tag{1.1}   p = s^* + \\epsilon \\end{equation}\\] overconfidence \\(oc^*\\) \\[\\begin{equation}   \\tag{1.2}   oc^* = s^*_s-s^* \\end{equation}\\] expected performance \\(p_e\\) \\[\\begin{equation}   \\tag{1.3}   p_e = s^* + oc^* \\end{equation}\\] Overconfidence \\(oc^*\\) measured overestimation \\(oe\\) defined \\[\\begin{equation}   \\tag{1.2}   oe = p_e - p \\end{equation}\\]","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/dunning-kruger.html","id":"theorems","dir":"Articles","previous_headings":"1 1. Implement the Theory > 1.3 Mathematical formulation","what":"Theorems","title":"FAIRifying the Dunning-Kruger Effect","text":"Theorem 1: \\[\\begin{equation} oe = oc^* - \\epsilon \\end{equation}\\] Proof: eq. (1.2) (1.3) follows \\(p_e = s^*_s\\) eq. (1.3) (1.1) see \\[\\begin{align}   \\tag{1.4}   oe &= p_e - p \\\\   &= (s^* + oc^*) - (s^* + \\epsilon) \\\\   &= oc^* - \\epsilon \\end{align}\\] Since accepted standard represent mathematical knowledge digital object (see also whitepaper), many possible routes FAIRify equations. opt representation latex code widely used known way typesetting equations. First, create file “equations.tex” containing actual derivations: , create file “render.tex” containing necessary information (document format, packages, commands) can used render equations: can see, use \\input{equations.tex} insert equations document. way, mathematical theory version controlled separately LaTex code required render . way, clear changes made theory (.e., equations.tex edited), changes made formatting theory (.e., render.tex edited).","code":"\\section{Definitions} Define random variables \\begin{itemize}  \\item $s^*$ denoting skill  \\item $\\epsilon$ denoting measurement error, with $\\Exp[\\epsilon] = 0$, $\\epsilon$ independent of all other random variables included in the model  \\item $s^*_s$ denoting self-assessed skill \\end{itemize}  \\noindent Then we define performance $p$ as \\begin{equation} \\label{p}   p \\coloneq s^* + \\epsilon \\end{equation} and overconfidence $oc^*$ as \\begin{equation} \\label{oc}   oc^* \\coloneq s^*_s-s^* \\end{equation} and expected performance $p_e$ as \\begin{equation} \\label{ep}   p_e \\coloneq s^* + oc^* \\end{equation} Overconfidence $oc^*$ is measured by overestimation $oe$ defined as \\begin{equation}   oe \\coloneq p_e - p \\end{equation}  \\section{Theorems}  Theorem 1:  \\begin{equation}   oe = oc^* - \\epsilon \\end{equation}  Proof 1: \\noindent From eq. \\ref{oc} and \\ref{ep} it follows that $p_e = s^*_s$ and further from eq. \\ref{ep} and \\ref{p} we see \\begin{align} \\label{dd}   oe &= p_e - p \\\\   &= (s^* + oc^*) - (s^* + \\epsilon) \\\\   &= oc^* - \\epsilon \\end{align} \\documentclass[a4paper,11pt]{article}  % load packages \\usepackage[utf8]{inputenc} \\usepackage{amsmath} \\usepackage{amssymb} \\usepackage{mathtools} \\usepackage{parskip}  % Statistics \\newcommand{\\Var}{\\mathbb{V}} \\newcommand{\\Exp}{\\mathbb{E}}  % commands \\renewcommand*{\\epsilon}{\\varepsilon}  % operators \\DeclareMathOperator{\\cov}{cov}  \\begin{document}  \\input{equations.tex}  \\end{document}"},{"path":"https://cjvanlissa.github.io/theorytools/articles/dunning-kruger.html","id":"statistical-models","dir":"Articles","previous_headings":"1 1. Implement the Theory","what":"Statistical Models","title":"FAIRifying the Dunning-Kruger Effect","text":"Using linear regression model, Dunning-Kruger effect can stated \\[\\begin{equation} oc^* = \\alpha + \\beta_1 s^* + u \\end{equation}\\] \\(\\beta_1 < 0\\). Substituting observable variables rearranging according eq. (1.1) (1.4): \\[\\begin{equation}   oe = \\alpha + \\beta_1 p + u - \\epsilon(1 + \\beta_1) \\end{equation}\\]","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/dunning-kruger.html","id":"correction","dir":"Articles","previous_headings":"1 1. Implement the Theory > 1.4 Statistical Models","what":"Correction","title":"FAIRifying the Dunning-Kruger Effect","text":"different ways correct bias introduced measurement error: Bias correction: use bias correction formula takes account correlation performance error term IV approach: measure performance second test (\\(p_2\\)) compute \\(\\beta_1 = \\frac{\\mathrm{cov}(oe, p_2)}{\\mathrm{cov}(p, p_2)}\\). Let’s add model latex code adding new file “linear_model.tex”: adding render.tex: now render render.tex, resulting document looks like :","code":"\\subsection{Linear Model} Using a linear regression model, the Dunning-Kruger effect can be stated as \\begin{equation}  oc^* = \\alpha + \\beta_1 s^* + u \\end{equation} with $\\beta_1 < 0$. Substituting the observable variables and rearranging according to eq. \\ref{p} and \\ref{dd}: \\begin{equation}   oe = \\alpha + \\beta_1 p + u - \\epsilon(1 + \\beta_1) \\end{equation}  \\subsubsection{Correction} There are different ways to correct for the bias introduced by measurement error: \\begin{itemize}  \\item Bias correction: use a bias correction formula that takes into account the correlation between performance and the error term  \\item IV approach: measure performance on a second test ($p_2$) and compute $\\beta_1 = \\frac{\\cov(oe, p_2)}{\\cov(p, p_2)}$. \\end{itemize} ... \\section{Statistical Models} \\input{linear_model.tex} ..."},{"path":"https://cjvanlissa.github.io/theorytools/articles/dunning-kruger.html","id":"overview","dir":"Articles","previous_headings":"1 1. Implement the Theory","what":"Overview","title":"FAIRifying the Dunning-Kruger Effect","text":"now folder containing following files: definitions.md relationship_graph.txt render.tex equations.tex linear_model.tex (Optionally:) render.pdf","code":""},{"path":[]},{"path":"https://cjvanlissa.github.io/theorytools/articles/dunning-kruger.html","id":"documenting-reusability-with-a-license","dir":"Articles","previous_headings":"2 2. Document the Theory","what":"Documenting Reusability with a LICENSE","title":"FAIRifying the Dunning-Kruger Effect","text":"add CC0 (Creative Commons Zero) license repository, waive copyright protection","code":"worcs::add_license_file(path = \".\", license = \"cc0\")"},{"path":"https://cjvanlissa.github.io/theorytools/articles/dunning-kruger.html","id":"documenting-interoperability-with-a-readme-file","dir":"Articles","previous_headings":"2 2. Document the Theory","what":"Documenting Interoperability with a README File","title":"FAIRifying the Dunning-Kruger Effect","text":"add README file describes repository’s contents purpose, making easier others understand theory’s potential interoperability reuse. First, include draft README file using: encourage users edit resulting README.md file, particular, add relevant information X-interoperability. case, X-interoperability limited: definitions definitions.txt yet well-defined (future work done ), equations equations.tex linear_model.tex interoperable formal mathematical operations, relationship_graph.txt can plotted using igraph R-package. Importantly, add references original paper Dunning Kruger, specification paper Feld colleagues: Feld, J., Sauermann, J., & De Grip, Andreas. 2017. “Estimating Relationship Skill Overconfidence.” Journal Behavioral Experimental Economics 68: 18–24. Kruger, J., & Dunning, D. (1999). Unskilled unaware : difficulties recognizing one’s incompetence lead inflated self-assessments. Journal personality social psychology, 77(6), 1121. guidance writing README file theory, see vignette.","code":"theorytools::add_readme_fair_theory(title = \"Dunning-Kruger Effect\",                                     path = \".\")"},{"path":"https://cjvanlissa.github.io/theorytools/articles/dunning-kruger.html","id":"add-zenodo-metadata","dir":"Articles","previous_headings":"2 2. Document the Theory","what":"Add Zenodo Metadata","title":"FAIRifying the Dunning-Kruger Effect","text":"Create .zenodo.json file metadata theory, allow indexed automatically archive Zenodo:","code":"theorytools::add_zenodo_json_theory(   path = \".\",   title = \"Dunning-Kruger Effect\",   keywords = c(\"Dunning–Kruger\", \"Overconfidence\", \"Judgment error\", \"Measurement error\") )"},{"path":[]},{"path":"https://cjvanlissa.github.io/theorytools/articles/dunning-kruger.html","id":"using-git-for-version-control","dir":"Articles","previous_headings":"3 3. Version Control the Theory","what":"Using Git for Version Control","title":"FAIRifying the Dunning-Kruger Effect","text":"use ‘Git’ version control project folder. yet set Git GitHub integration computer, reference basic FAIR theory tutorial. Initialize version control project repository running:","code":"gert::git_init(path = \".\")"},{"path":"https://cjvanlissa.github.io/theorytools/articles/dunning-kruger.html","id":"connecting-to-a-remote-github-repository","dir":"Articles","previous_headings":"3 3. Version Control the Theory","what":"Connecting to a Remote (‘GitHub’) Repository","title":"FAIRifying the Dunning-Kruger Effect","text":"make FAIR theory accessible collaborators discoverable wider community, must connect local ‘Git’ repository remote repository platform like ‘GitHub’: command create new public repository ‘GitHub’ link local repository. private = FALSE argument ensures repository public default. Connect repository FAIR theory folder follows: Finally, push local files remote repository:","code":"worcs::git_remote_create(\"dunning_kruger\", private = FALSE) worcs::git_remote_connect(\".\", remote_repo = \"dunning_kruger\") worcs::git_update(\"First commit of my theory\", repo = \".\")"},{"path":"https://cjvanlissa.github.io/theorytools/articles/dunning-kruger.html","id":"archive-the-theory-on-zenodo","dir":"Articles","previous_headings":"","what":"4. Archive the Theory on ‘Zenodo’","title":"FAIRifying the Dunning-Kruger Effect","text":"Head zenodo.org. Authorize Zenodo connect ‘GitHub’ account ‘Using ’GitHub’’ section. , ‘Zenodo’ redirect ‘GitHub’ ask permissions use ‘webhooks’ repositories. want authorize ‘Zenodo’ permissions needs form links. Navigate ‘GitHub’ repository listing page “flip switch” next repository. repository show list, may need press ‘Synchronize now’ button. time writing, noticed can take quite (hours?) ‘Zenodo’ detect new ‘GitHub’ repositories. , take break come back last step tomorrow!","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/dunning-kruger.html","id":"entering-meta-data","dir":"Articles","previous_headings":"","what":"5. Entering Meta-Data","title":"FAIRifying the Dunning-Kruger Effect","text":"can document ‘Zenodo’ archive FAIR theory adding extra information ‘Zenodo’. ‘Zenodo’ click Upload tab main menu, find newly uploaded repository. metadata pre-populated .zenodo.json file. additionally add several related works. example: + derived Journal article: 10.1016/j.socec.2017.03.002 (DOI) + derived Journal article: 10.1037/0022-3514.77.6.1121 (DOI) Finally, click “Publish” update metadata. end result tutorial FAIR theory like one: https://doi.org/10.5281/zenodo.15633859","code":""},{"path":[]},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"creating-a-fair-theory","dir":"Articles","previous_headings":"","what":"Creating a FAIR Theory","title":"Making a Theory FAIR","text":"tutorial takes user distinct steps involved making theory FAIR. uses R-package theorytools specific software platforms. open science infrastructure area active development, approach proposed considered definitive, rather, one proposal FAIR-compliant implementation theory using infrastructure available time writing. steps described tutorial largely automated function theorytools::create_fair_theory(); expert users might use function directly.","code":"library(theorytools)"},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"time-to-complete","dir":"Articles","previous_headings":"Creating a FAIR Theory","what":"Time to Complete","title":"Making a Theory FAIR","text":"Estimated time complete: 45-60 minutes.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"learning-goals","dir":"Articles","previous_headings":"Creating a FAIR Theory","what":"Learning Goals","title":"Making a Theory FAIR","text":"Create project folder theory Put folder version control ‘Git’ Connect local repository remote (‘GitHub’) repository Add shareable theory file repository Add LICENSE file repository (recommend CC0) Add README file repository Add ‘Zenodo’ metadata repository Push changes remote repository Turn ‘Zenodo’ archiving remote repository Publish release theory Verify ‘Zenodo’ mints DOI theory latest release Conceptual workflow task.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"running-example-the-empirical-cycle","dir":"Articles","previous_headings":"Creating a FAIR Theory","what":"Running Example: the Empirical Cycle","title":"Making a Theory FAIR","text":"Given based argument importance FAIR theory empirical cycle, use example tutorial. empirical cycle model cumulative knowledge production scientific research, described De Groot Spiekerman (1969) (p. 28): Phase 1: ‘Observation’: collection grouping empirical materials; (tentative) formation hypotheses.Phase 2: ‘Induction’: formulation hypotheses.Phase 3: ‘Deduction’: derivation specific consequences hypotheses, form testable predictions.Phase 4: ‘Testing’: hypotheses new empirical materials, way checking whether predictions fulfilled.Phase 5: ‘Evaluation’: outcome testing procedure respect hypotheses theories stated, well view subsequent, continued related, investigations.","code":""},{"path":[]},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"creating-a-project-folder","dir":"Articles","previous_headings":"Completing All Steps Manually","what":"Creating a Project Folder","title":"Making a Theory FAIR","text":"spirit modular publishing, tutorial assumes ’re creating FAIR theory standalone project. possible theory implemented programming language like R, often - empirical cycle described implemented plain text. Therefore, create R project (.Rproj file et cetera), just regular nondescript project. starts creating empty project folder, become theory archive. want create new folder called empirical_cycle existing folder c:/theories/, can call:","code":"project_path <- file.path(\"c:/theories\", \"empirical_cycle\") dir.create(project_path)"},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"adding-a-shareable-theory-file-to-the-repository","dir":"Articles","previous_headings":"Completing All Steps Manually","what":"Adding a Shareable Theory File to the Repository","title":"Making a Theory FAIR","text":"theory represented digital artifact, structured plain-text document machine-readable file (e.g., ‘DOT’, ‘JSON’, ‘YAML’, ‘R’ code). point, offer two alternatives.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"theory-as-plain-text","dir":"Articles","previous_headings":"Completing All Steps Manually > Adding a Shareable Theory File to the Repository","what":"Theory as Plain Text","title":"Making a Theory FAIR","text":"simply copy De Groot’s implementation empirical cycle plain text file, like :","code":"writeLines(   c(\"*Phase 1:* 'Observation': collection and grouping of empirical materials;     (tentative) formation of hypotheses.\",     \"*Phase 2:* 'Induction': formulation of hypotheses.\",      \"*Phase 3:* 'Deduction': derivation of specific consequences     from the hypotheses, in the form of testable predictions.\",     \"*Phase 4:* 'Testing': of the hypotheses against new empirical materials,     by way of checking whether or not the predictions are fulfilled.\",     \"*Phase 5:* 'Evaluation': of the outcome of the testing procedure     with respect to the hypotheses or theories stated, as well as     with a view to subsequent, continued or related, investigations.\" ), file.path(project_path, \"theory.txt\"))"},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"implementing-the-theory-in-a-formal-language","dir":"Articles","previous_headings":"Completing All Steps Manually > Adding a Shareable Theory File to the Repository","what":"Implementing the Theory in a Formal Language","title":"Making a Theory FAIR","text":"compare levels theory formalization (Guest Martin 2021), De Groot’s theory either “theory” “specification” level. consists series natural language statements. can increase level formalization, present “implementation” human- machine-readable DOT language, thereby meeting criterion I1 FAIR principles (“using formal language knowledge representation”): language describes model directed graph. Note code organized first half describes ontology entities theory postulates, second half describes proposed interrelations. follows first two properties good theory according Meehl (Meehl 1990). Git tracks changes line--line basis, separating ontology structural parts theory facilitates tracking changes either . can now write implementation empirical cycle text file, say empirical_cycle.dot.","code":"theory <-  \"digraph {    observation;   induction;   deduction;   test;   evaluation;      observation -> induction;   induction -> deduction;   deduction -> test;   test -> evaluation;   evaluation -> observation;    }\" cat(theory, file = file.path(project_path, \"empirical_cycle.dot\"), sep = \"\\n\")"},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"documenting-reusability-with-a-license","dir":"Articles","previous_headings":"Completing All Steps Manually","what":"Documenting Reusability with a LICENSE","title":"Making a Theory FAIR","text":"license ensures others know can legally reuse work. recommend CC0 (Creative Commons Zero) license FAIR theory, waives copyright protection places work public domain. recommendation based fact copyright protection cover ideas, assumption FAIR theory created maximize reuse. licenses available, see https://choosealicense.com. can add license file repository like :","code":"worcs::add_license_file(path = project_path, license = \"cc0\")"},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"documenting-interoperability-with-a-readme-file","dir":"Articles","previous_headings":"Completing All Steps Manually","what":"Documenting Interoperability with a README File","title":"Making a Theory FAIR","text":"README file describes repository’s contents purpose, making easier others understand theory’s potential interoperability reuse. theorytools package contains function generate README file appropriate sections FAIR theory, can used like : encourage users edit resulting README.md file, particular, add relevant information X-interoperability. guidance writing README file theory, see vignette.","code":"theorytools::add_readme_fair_theory(title = \"The Empirical Cycle\",                                     path = project_path)"},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"adding-zenodo-metadata-to-the-repository","dir":"Articles","previous_headings":"Completing All Steps Manually","what":"Adding ‘Zenodo’ Metadata to the Repository","title":"Making a Theory FAIR","text":"later step, archive theory ‘Zenodo’. Creating .zenodo.json file metadata theory allows project indexed automatically. can done running:","code":"add_zenodo_json_theory(   path = project_path,   title = \"The Empirical Cycle\",   keywords = c(\"philosophy of science\", \"methodology\") )"},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"version-controlling-the-project-folder","dir":"Articles","previous_headings":"Completing All Steps Manually","what":"Version Controlling The Project Folder","title":"Making a Theory FAIR","text":"use ‘Git’ version control project folder. already ‘Git’ installed computer, install now. can verify ‘Git’ installed working running: function shows green checkmark, can initialize version control project repository running:","code":"worcs::check_git() gert::git_init(path = project_path)"},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"connecting-to-a-remote-github-repository","dir":"Articles","previous_headings":"Completing All Steps Manually","what":"Connecting to a Remote (‘GitHub’) Repository","title":"Making a Theory FAIR","text":"make FAIR theory accessible collaborators discoverable wider community, must connect local ‘Git’ repository remote repository platform like ‘GitHub’. proceeding, ensure ‘GitHub’ account. Academics may qualify free upgrade. authorize ‘R’ interact ‘GitHub’ account, run usethis::create_github_token(), takes website create personal access token (PAT). Copy , run gitcreds::gitcreds_set() paste PAT asked. still experience problems try usethis::gh_token_help() help. check ready proceed, run: see green checkmark, can create new repository ‘GitHub’ directly ‘R’: command create new public repository ‘GitHub’ link local repository. private = FALSE argument ensures repository public default. Alternatively, may already created remote repository ‘GitHub’ website. Either way, assuming name repository empirical_cycle, can connect project folder follows:","code":"worcs::check_github() worcs::git_remote_create(\"empirical_cycle\", private = FALSE) worcs::git_remote_connect(project_path, remote_repo = \"empirical_cycle\")"},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"pushing-these-changes-to-the-remote-repository","dir":"Articles","previous_headings":"Completing All Steps Manually","what":"Pushing These Changes to the Remote Repository","title":"Making a Theory FAIR","text":"Version control requires adding files tracked repository (gert::git_add()), committing changes files (gert::git_commit()), pushing remote repository (gert::git_push()). worcs function worcs::git_update() combines three actions, acting like kind “quick-save” function:","code":"worcs::git_update(\"First commit of my theory\", repo = project_path)"},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"check-your-github-repository","dir":"Articles","previous_headings":"Completing All Steps Manually","what":"Check Your ‘GitHub’ Repository","title":"Making a Theory FAIR","text":"Navigate repository ‘GitHub’ check committed files, including theory file, license, README, ‘Zenodo’ metadata, now visible remote repository (green box image ). Front Page ‘GitHub’ Repository Furthermore, repository visibility must set “Public” ensure ‘Zenodo’ can discover archive . created repository programmatically shown , already public (see red box image ). necessary, change visibility setting Public clicking “Settings” > “General” > “Change repository visibility.”","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"login-to-zenodo","dir":"Articles","previous_headings":"Completing All Steps Manually","what":"Login to ‘Zenodo’","title":"Making a Theory FAIR","text":"Head zenodo.org. ‘Zenodo’ platform can permanently archive code project elements. ‘Zenodo’ assigning projects Digital Object Identifier (DOI), also helps make work citable. different ‘GitHub’, acts place actual work project takes place, rather long-term archiving . ‘GitHub’, content can modified, deleted, rewritten, irreversibly changed, makes bit concerning used longer lasting referencing purposes. ‘Zenodo’ offers security permanence research outputs. Sign ‘Zenodo’ already ‘Zenodo’ account, easy. , follow steps create one — can login using ‘GitHub’ account.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"authorize-github-to-connect-with-zenodo","dir":"Articles","previous_headings":"Completing All Steps Manually","what":"Authorize ‘GitHub’ to connect with ‘Zenodo’","title":"Making a Theory FAIR","text":"‘Zenodo’ website authorize connect ‘GitHub’ account ‘Using ’GitHub’’ section. , ‘Zenodo’ redirect ‘GitHub’ ask permissions use ‘webhooks’ repositories. want authorize ‘Zenodo’ permissions needs form links. Authorize connect ‘GitHub’","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"select-the-repository-to-archive","dir":"Articles","previous_headings":"Completing All Steps Manually","what":"Select the Repository to Archive","title":"Making a Theory FAIR","text":"got far, means ‘Zenodo’ now authorized configure repository webhooks needs archive repository issue DOI. , ‘Zenodo’ website navigate ‘GitHub’ repository listing page simply “flip switch” next repository. repository show list, may need press ‘Synchronize now’ button. time writing, noticed can take quite (hours?) ‘Zenodo’ detect new ‘GitHub’ repositories. , take break come back last step tomorrow! Enable individual ‘GitHub’ repositories archived ‘Zenodo’","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"optional-check-repository-settings","dir":"Articles","previous_headings":"Completing All Steps Manually","what":"Optional: Check repository settings","title":"Making a Theory FAIR","text":"successful, now set new webhook ‘Zenodo’ repository. Optionally, can verify . ‘GitHub’, click settings repository, Webhooks tab left hand side menu. display new ‘Zenodo’ webhook configured ‘Zenodo’. Note, may take little time webhook listing show . Check webhooks enabled ‘GitHub’ repository.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"create-a-new-release","dir":"Articles","previous_headings":"Completing All Steps Manually","what":"Create a New Release","title":"Making a Theory FAIR","text":"archive repository ‘Zenodo’, must create new release. can using following code: previously published releases, function assume want use semantic versioning release tag release title. means first release labeled version number “0.1.0”. subsequent release automatically increment trailing digit, .e.: “0.1.1”, “0.1.2”. make major change theory, may want manually increment middle digit like :","code":"worcs::git_release_publish(repo = project_path) worcs::git_release_publish(repo = project_path,                            tag_name = \"0.2.0\",                            release_name = \"0.2.0\")"},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"verify-on-zenodo","dir":"Articles","previous_headings":"Completing All Steps Manually","what":"Verify on ‘Zenodo’","title":"Making a Theory FAIR","text":"verify release archived ‘Zenodo’ assigned DOI, need visit Uploads tab. Check new release uploaded.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"updating-meta-data","dir":"Articles","previous_headings":"Completing All Steps Manually","what":"Updating Meta-Data","title":"Making a Theory FAIR","text":"can document ‘Zenodo’ archive FAIR theory adding extra information ‘Zenodo’. Note , created .zenodo.json file previous step, metadata populated automatically. ‘Zenodo’ click Upload tab main menu, find newly uploaded repository. Click orange Edit button. Click orange Edit button, verify/supply following information: Resource type: set Model Title: prefaced FAIR theory: Keywords subjects: first keyword fairtheory Related works: Add DOIs/identifiers related (print) works. Use Relation field appropriate. example: documented theory paper wrote, introduce FAIR theory derived existing theory, published print (paper, book chapter) made FAIR References: Optionally, cite related works plain text. example, can provide full citation De Groot Spiekerman: De Groot, . D., & Spiekerman, J. . . (1969). Methodology: Foundations inference research behavioral sciences. De Gruyter Mouton. https://doi.org/10.1515/9783112313121 save changes, click ‘Publish’.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"verifying-that-zenodo-mints-a-doi-for-your-theory","dir":"Articles","previous_headings":"Completing All Steps Manually","what":"Verifying That ‘Zenodo’ Mints a DOI for Your Theory","title":"Making a Theory FAIR","text":"publishing release, ‘Zenodo’ archive repository mint DOI. Verify checking ‘Zenodo’ entry repository, DOI displayed. Include DOI citations references theory enhance discoverability reusability. ‘GitHub’/‘Zenodo’ integration assign one “mother-DOI” project, always resolve latest version, well unique DOI version/release FAIR theory. enables users refer cite either theory general specific versions theory. list authors citation automatically determined ‘GitHub’ user account names used repository - can edited ‘Zenodo’, explained . DOIs used ‘Zenodo’ registered DataCite service. Pro-tip: Check Citation field ‘Zenodo’ page, copy-paste README file ‘GitHub’ repo make cross-linking even easier (refer users ‘Zenodo’ page find citation, obviates need manually update information). Click DOI badge Details field get instructions add clear highlighted DOI badge ‘GitHub’ repository, users see make use DOI:","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"congratulations","dir":"Articles","previous_headings":"Completing All Steps Manually","what":"CONGRATULATIONS!","title":"Making a Theory FAIR","text":"FAIR theory now archived ‘Zenodo’, DOI can versioned reflect updates repository version time. able see details ‘GitHub’ ‘Zenodo’ page repository. also means archived projects can get picked indexing services search engines use DOIs . Providing long-term archive DOI work required others able properly cite , provides basic citation metadata. Open Science, important able comprehensively cite resources use research, including theory, workflow enables happen, line best practices. Making theory FAIR also helps elevate standard theory standard research outputs, like papers software. Pro-tip: research funded EU grant? Now can directly connect FAIR theory grant updating grant section metadata project’s ‘Zenodo’ record. massively helps increase discoverability!","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"checklist-for-citing-your-project","dir":"Articles","previous_headings":"Completing All Steps Manually","what":"Checklist for citing your project","title":"Making a Theory FAIR","text":"now sustainably archived ‘GitHub’ repository ‘Zenodo’ ready re-used cited! continuing, make sure : Linked ‘GitHub’ project ‘Zenodo’. see complete copy ‘GitHub’ repository ‘Zenodo’ things working. ‘Zenodo’ ‘GitHub’ integrated setup works nicely. example author names, correct project title come across ‘Zenodo’. , authors just nicknames can edit details ‘Zenodo’. Project first release, DOI. DOI displayed projects ‘Zenodo’ page. first DOI called ‘concept DOI’ master DOI linking subsequent release DOIs. Copy DOI link embed ‘GitHub’ projects README page. ’re done!","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"automating-fair-theory-creation","dir":"Articles","previous_headings":"","what":"Automating FAIR Theory Creation","title":"Making a Theory FAIR","text":"function theorytools::create_fair_theory() automates preceding steps, step 2.8. Assuming already created shareable theory file called theory.txt resides currently active directory (getwd()), can create FAIR theory follows: still complete steps 2.12 - 2.17 manually.","code":"create_fair_theory(   path = file.path(\"c:/theories\", \"empirical_cycle\"),   title = \"The Empirical Cycle, Again\",   theory_file = \"theory.txt\",   remote_repo = \"empirical_cycle2\",   add_license = \"cc0\")"},{"path":"https://cjvanlissa.github.io/theorytools/articles/fair-theory.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Making a Theory FAIR","text":"tutorial partly adapted Module 5, Task 2 Tennant et al. (2018).","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/formalizing_sdt.html","id":"time-to-complete","dir":"Articles","previous_headings":"","what":"Time to Complete","title":"Formalizing Self-Determination Theory","text":"Estimated time complete: 45-60 minutes.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/formalizing_sdt.html","id":"learning-goals","dir":"Articles","previous_headings":"","what":"Learning Goals","title":"Formalizing Self-Determination Theory","text":"Translate theory described prose series -propositions Document construct definitions operationalizations theory Translate -propositions Directed Acyclic Graph Publish resulting theory FAIR Theory Zenodo","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/formalizing_sdt.html","id":"step-1-select-relevant-sources","dir":"Articles","previous_headings":"","what":"Step 1: Select Relevant Sources","title":"Formalizing Self-Determination Theory","text":"first step PBTS procedure, asked select sources theory specification agree sources fellow raters; detect relevant text snippets within sources contain descriptions definitions, causal relations, et cetera proposed theory; agree fellow coders snippets. decided use book chapter source. example, first snippet selected : “natural, active processes intrinsic motivation integration operate effectively toward healthy development psychological well-, human beings need particular nutriments – biological psychological (Ryan, 1995). relative absence nutriments, natural processes impaired, resulting experiences, development, behaviors less optimal. (Deci & Ryan, 2012, p. 417) Expand section see selected snippets: Snippet 1: “natural, active processes intrinsic motivation integration operate effectively toward healthy development psychological well-, human beings need particular nutriments – biological psychological (Ryan, 1995). relative absence nutriments, natural processes impaired, resulting experiences, development, behaviors less optimal. (Deci & Ryan, 2012, p. 417) Snippet 2: “three basic psychological needs universal satisfaction versus thwarting affects psychological well-people.” (Deci & Ryan, 2012, p. 425) Snippet 3: “rewards always motivate subsequent persistence; indeed can undermine intrinsic motivation” (Deci & Ryan, 2012, p. 417) Snippet 4: “[Intrinsic motivation] either undermined enhanced depending whether social environment supported thwarted needs competence self-determination. reward external event threat punishment (Deci Cascio, 1972), positive feedback (Deci, 1971), competition (Deci Betley et al., 1981), choice (Zuckerman et al., 1978) expected thwart basic needs, predicted prompt external perceived locus causality undermine intrinsic motivation; event expected support basic needs, predicted prompt internal perceived locus causality enhance intrinsic motivation.” (Deci & Ryan, 2012, p. 418)","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/formalizing_sdt.html","id":"step-2-extract-if-then-propositions","dir":"Articles","previous_headings":"","what":"Step 2: Extract IF-THEN Propositions","title":"Formalizing Self-Determination Theory","text":"individual coder set extract set -propositions selected snippets , together, describe theory. Let’s examine first snippet, code implied causality. causes coded green, outcomes blue: “natural, active processes intrinsic motivation integration operate effectively toward healthy development psychological well-, human beings need particular nutriments – biological psychological (Ryan, 1995). relative absence nutriments, natural processes impaired, resulting experiences, development, behaviors less optimal” (Lange et al., 2012, p. 417) text bit ambiguous, possibly redundant. see processes, first sentence, refers intrinsic motivation integration. invites question relationship intrinsic motivation integration - go hand hand (.e., just two examples processes set motion nutriments)? distinct similarly related constructs? ’s clear. Furthermore, second sentence, find word processes , time without explicit reference intrinsic motivation integration. now, assume intrinsic motivation integration distinct similar relationships constructs, word used consistently across sentences. Nutriments defined elsewhere text - appears refer refer three basic needs, well biological necessities. Experiences, development, behaviors well-defined, might assume refers back healthy development psychological well-. reconstruct implied propositions follows: Processes (intrinsic motivation integration) -> healthy development psychological well-(processes intrinsic motivation integration [operate effectively toward] healthy development psychological well-) Nutriments -> Processes (human beings [need] nutriments […] processes operate etc.) Nutriments -> Processes ([absence ] nutriments […] processes impaired) Processes -> Healthy development psychological well-(processes impaired, resulting experiences, development, behaviors) Assuming interpretations correct, see snippet redundantly states two relationships twice; phrased positive negative. Let’s apply coding procedure snippets: SDT translated /statements","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/formalizing_sdt.html","id":"from-if-then-propositions-to-causal-model","dir":"Articles","previous_headings":"Step 2: Extract IF-THEN Propositions","what":"From IF-THEN Propositions to Causal Model","title":"Formalizing Self-Determination Theory","text":"-specification prescribed PBTS framework limitations ; example, well-suited describe difference degrees (people affected little bit), probabilistic effect (people affected, ). Except proposition #3, explicitly states people universally affected, none original statements appear binary. However, direction causality relatively clear. Thus, better fit might Directed Acyclic Graph (DAG), incurs additional advantage X-interoperable covariate selection data generation (see vignette). can translate -statements causal links specific constructs. result contained file included theorytools package, load . Note numbers associated statements retained, clear causal links derived /statements: /statements translated causal connections translation reveals ambiguities; example, proposition #4, see “rewards” related intrinsic motivation. However, remainder text, rewards mentioned just one example “external events”. assumed “rewards” used example broader class external events. Another ambiguity: read “[external event] expected thwart [basic needs], [prompts] external perceived locus causality”. Since theory otherwise explain people might “expect” external events affect , seems question cognitive social psychology - made simplifying assumption: external events affect needs, also perceived locus causality. specification also reveals redundancies original theory. Many propositions repeated, phrased positive way, phrased negative way. can confusing, especially two phrasings differ slightly; example, snippet #1, positive phrasing refers “healthy development psychological well-” ultimate outcome need satisfaction, negative phrasing refers “experiences, development, behaviors” ultimate outcomes need frustration. seems safe assume sentences meaning, ambiguity . statements reduced implied causal connections, redundancies become readily apparent. can simply remove redundancies follows: Unique causal connections can translate table DAG: can plot DAG follows: Causal diagram implied SDT","code":"SDT <- read.csv(system.file(\"sdt.txt\", package=\"theorytools\")) knitr::kable(SDT[, 1:3], caption = \"IF/THEN statements translated into causal connections\") # Drop statement numbers SDT <- SDT[, 2:3] # Remove redundant statements SDT <- SDT[!duplicated(SDT), ] knitr::kable(SDT, caption = \"Unique causal connections\") SDT <- dagitty::dagitty(   paste0(\"dag {\",   paste0(SDT$from, \" -> \", SDT$to, collapse = \"\\n\"),   \"}\") ) library(tidySEM) library(ggplot2) # Specify plot layout lo <- get_layout( \"EE\", \"\",   \"IN\", \"WB\", \"\",   \"LC\", \"\",   \"\", \"NE\", \"\",   \"IM\", \"HD\",   rows = 3 ) # Rename nodes renam <- c(EE = \"external_event\", NE = \"needs\", IN = \"integration\", WB = \"wellbeing\",             LC = \"locus_of_causality\", HD = \"healthy_development\", IM = \"intrinsic_motivation\") lo[match(names(renam), lo)] <- renam # Prepare the graph p <- prepare_graph(SDT, layout = lo, angle = 179, text_size = 3, rect_width = 1.5, spacing_x = 2.5)  # Change node shape p$nodes$shape <- \"rect\" # Change node labels renam <- c(external_event = \"external\\nevent\", needs = \"needs\", integration = \"integration\", wellbeing = \"wellbeing\",             locus_of_causality = \"locus of\\ncausality\", healthy_development = \"healthy\\ndev.\", intrinsic_motivation = \"intrinsic\\nmotivation\") p$nodes$label <- renam[p$nodes$name] # Plot the graph plot(p)"},{"path":"https://cjvanlissa.github.io/theorytools/articles/formalizing_sdt.html","id":"step-3--define-and-operationalize-concepts","dir":"Articles","previous_headings":"","what":"Step 3. Define and Operationalize Concepts","title":"Formalizing Self-Determination Theory","text":"step, asked add definitions concept referred author theory. principle, asked refer text snippets sources determined Step 1. However, case definitions provided author (case constructs theory), allowed derive scientific literature. operationalizations derived relevant sources, coded missing. resulting definitions stored inside theorytools package can load follows: Operationalizations constructs SDT can seen fom overview - none definitions given theory chapter. able trace definitions empirical papers cited chapter, definitions appeared fall short proper “theoretical definitions”. example, intrinsic motivation defined “number seconds spent working puzzle”. purely behaviorist definition internal state. words: theory relatively explicit causal links constructs (just ambiguities), appears important work remains done terms defining constructs involved theory. possible likely domain experts able easily resolve ambiguities definitions, best . now create FAIR theory archive, invite others develop theory.","code":"definitions <- read.csv(system.file(\"sdt_definitions.csv\",package=\"theorytools\")) definitions"},{"path":"https://cjvanlissa.github.io/theorytools/articles/formalizing_sdt.html","id":"archiving-sdt-as-fair-theory","dir":"Articles","previous_headings":"","what":"Archiving SDT as FAIR Theory","title":"Formalizing Self-Determination Theory","text":"automate steps FAIR theory creation; go process manually, see vignette). Let’s create two files theory: DAG specify causal relations, spreadsheet containing definitions. Next, can create FAIR theory follows: manually complete following steps: Update README file Connect GitHub Zenodo Push local updates GitHub Publish release GitHub, triggers release Zenodo","code":"writeLines(SDT, \"sdt.txt\") write.csv(definitions, \"definitions.csv\", row.names = FALSE) project_path <- file.path(\"c:/theories\", \"self_determination_theory\") create_fair_theory(   path = project_path,   title = \"Self-Determination Theory\",   theory_file = c(\"sdt.txt\", \"definitions.csv\"),   remote_repo = \"self_determination_theory\",   add_license = \"cc0\")"},{"path":"https://cjvanlissa.github.io/theorytools/articles/formalizing_sdt.html","id":"documenting-interoperability-with-a-readme-file","dir":"Articles","previous_headings":"Archiving SDT as FAIR Theory","what":"Documenting Interoperability with a README File","title":"Formalizing Self-Determination Theory","text":"customized README adding sections: Description FAIR theory (Van Lissa et al., 2025) specification Deci Ryan’s Self-Determination Theory (Deci & Ryan, 2012). definition SDT used theory specification exercise taken book chapter, seems fully consistent description https://selfdeterminationtheory.org/-theory/. theory first specified Van Lissa, Li, Weber part “Proposition Based Theory Specification” (PBTS) project Andreas Glöckner, Susann Fiedler, Jennifer Biehl, & Jasper Siol (preparation). “many-theorists project”, groups scholars assigned chapter “Handbook Theories Social Psychology” (Van Lange, Kruglanski, Higgins 2012), asked specify document process. Van Lissa adapted theory specification, documented vignette. Interoperabilitysdt.txt file contains main theory, specified DAG. interoperable causal inference data simulation R, explained vignette.definitions.csv file contains definitions constructs sdt.txt able find. present, file interoperable. urgently invite domain experts propose concrete definitions constructs (attempt identify intended definitions likely fell short), propose new better definitions. Related works Deci, E. L., & Ryan, R. M. (2012). Self-Determination Theory. P. . M. V. Lange, . W.Kruglanski, & E. ToryHiggins (Eds.), Handbook Theories Social Psychology: Volume 1 (pp. 416–437). SAGE Publications Ltd. https://doi.org/10.4135/9781446249215","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/formalizing_sdt.html","id":"authorize-github-to-connect-with-zenodo","dir":"Articles","previous_headings":"Archiving SDT as FAIR Theory","what":"Authorize ‘GitHub’ to connect with ‘Zenodo’","title":"Formalizing Self-Determination Theory","text":"‘Zenodo’ website navigate ‘GitHub’ repository listing page simply “flip switch” next repository. repository show list, may need press ‘Synchronize now’ button. time writing, noticed can take quite (hours?) ‘Zenodo’ detect new ‘GitHub’ repositories. , take break come back last step tomorrow! Enable individual ‘GitHub’ repositories archived ‘Zenodo’ Flip switch set new webhook ‘Zenodo’ repository.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/formalizing_sdt.html","id":"create-a-new-release","dir":"Articles","previous_headings":"Archiving SDT as FAIR Theory","what":"Create a New Release","title":"Formalizing Self-Determination Theory","text":"archive repository ‘Zenodo’, must create new release. Since changed README file, first, add, commit, push changes remote repository using git_update(). , publish release using git_release_publish():","code":"worcs::git_update(repo = project_path) worcs::git_release_publish(repo = project_path)"},{"path":"https://cjvanlissa.github.io/theorytools/articles/formalizing_sdt.html","id":"updating-zenodo-meta-data","dir":"Articles","previous_headings":"Archiving SDT as FAIR Theory","what":"Updating Zenodo Meta-Data","title":"Formalizing Self-Determination Theory","text":"can document ‘Zenodo’ archive FAIR theory adding extra information ‘Zenodo’. Note , created .zenodo.json file previous step, metadata populated automatically. ‘Zenodo’ click Upload tab main menu, find newly uploaded repository. Click orange Edit button. Click orange Edit button, verify/supply following information: Keywords: Following paper Deci & Ryan (2008), added keywords self-determination theory, autonomous motivation, personality development. Related works: added DOI book chapter Deci & Ryan (2012), relation derived , well DOIs papers referenced definitions.csv, relation type References. citing DOIs inside file renders Accessible Interoperable sentient readers, additionally documenting DataCite metadata makes Accessible Interoperable library systems scholarly analytics software. save changes, click ‘Publish’. View final result, FAIR Self-Determination Theory, https://doi.org/10.5281/zenodo.15648655.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/readme.html","id":"title","dir":"Articles","previous_headings":"","what":"1. Title","title":"What to Include in a README?","text":"Provide clear title theory. recommend prefacing title words FAIR theory:, just like systematic review words systematic review title, help sentient readers immediately identify .","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/readme.html","id":"description","dir":"Articles","previous_headings":"","what":"2. Description","title":"What to Include in a README?","text":"Provide plain-text description theory scope. one- two-sentence summary theory explains predicts, context field study theory applies.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/readme.html","id":"interoperability","dir":"Articles","previous_headings":"","what":"3. Interoperability","title":"What to Include in a README?","text":"README files contain section labeled “Getting Started”, “Instructions Use”, “Use”. FAIR perspective, section might better labeled “Interoperability”. propose using section explicitly address theory’s X-interoperability, telling users exactly can use theory , . X-interoperability: Tells can theory, .","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/readme.html","id":"contributing","dir":"Articles","previous_headings":"","what":"4. Contributing","title":"What to Include in a README?","text":"Pertaining Reusability criterion FAIR principles, section tell users social expectations regarding reuse contributions.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/readme.html","id":"license","dir":"Articles","previous_headings":"","what":"5. License","title":"What to Include in a README?","text":"legal complement preceding Contributing section, section refer readers LICENSE file learn legal conditions reuse.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/readme.html","id":"citing-this-work","dir":"Articles","previous_headings":"","what":"6. Citing this Work","title":"What to Include in a README?","text":"Tell users cite theory. Note section redundant Zenodo archive, preferred citation field. disadvantage redundant information may maintain section README going forward. advantage documenting related works README makes readily accessible users. suggest compromise: retain section, use direct reader preferred citation Zenodo page.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/readme.html","id":"related-works","dir":"Articles","previous_headings":"","what":"7. Related Works","title":"What to Include in a README?","text":"section refer work FAIR theory derived , documented . , redundant metadata entered Zenodo. nevertheless recommend using section direct reader Zenodo, optionally, document one canonical reference theory unlikely change going forward.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/readme.html","id":"example-the-empirical-cycle","dir":"Articles","previous_headings":"","what":"Example: The Empirical Cycle","title":"What to Include in a README?","text":", break README file implementation De Groot’s empirical cycle FAIR theory: title prefaced FAIR theory: description gives information theory scope: Interoperability section tells readers theory implemented, ways can reused: specific instructions contribute project: Related Works section gives one canonical reference, directs readers Zenodo: preferred citation section directs readers Zenodo prevent redundancy:","code":"# FAIR theory: The Empirical Cycle ## Description  This is a FAIR implementation of De Groot and Spiekerman's \"empirical cycle\" theory, a theory of cumulative knowledge acquisition through scientific research. ## Interoperability  The theory is implemented in the DOT language for describing graphs.  ### Rendering the theory using graphviz  See the graphviz manual for more information: https://graphviz.org ## Contributing  If you want to contribute to this project, please get involved. You can do so in three ways:  1. **To discuss the current implementation and discuss potential changes**, file a ‘GitHub’ issue [here](https://github.com/cjvanlissa/empirical_cycle/issues) 2. **To directly propose changes**, send a pull request containing the proposed changes [here](https://github.com/cjvanlissa/tidySEM/pulls) 3. **To create a derivative theory**, please fork the repository [here](https://github.com/cjvanlissa/empirical_cycle/fork). Please cite this repository (see below), and add this repository as a related work (below and by adding the appropriate metadata on Zenodo).  By participating in this project, you agree to abide by the [Contributor Covenant](https://www.contributor-covenant.org/version/2/0/code_of_conduct.html). ## Related Works  See this project's Zenodo page for cross-references to related work.   This repository contains an implementation of the \"empirical cycle\", a model proposed by De Groot and Spiekerman (1969, p. 28)  > De Groot, A. D., & Spiekerman, J. A. A. (1969). Methodology: Foundations of inference and research in the behavioral sciences. De Gruyter Mouton. https://doi.org/10.1515/9783112313121 ## Citing this work  See [this project's Zenodo page](https://doi.org/10.5281/zenodo.14552329) for the preferred citation."},{"path":"https://cjvanlissa.github.io/theorytools/articles/readme.html","id":"complete-readme","dir":"Articles","previous_headings":"Example: The Empirical Cycle","what":"Complete Readme","title":"What to Include in a README?","text":"complete resulting readme.MD shown (click expand). including sections, README file serve robust guide understanding, using, extending FAIR theory, ensuring accessibility reusability diverse audiences.","code":"# FAIR theory: The Empirical Cycle  ## Description  This is a FAIR implementation of De Groot and Spiekerman's \"empirical cycle\" theory, a theory of cumulative knowledge acquisition through scientific research.  ## Interoperability  The theory is implemented in the DOT language for describing graphs.  ### Rendering the theory using graphviz  See the graphviz manual for more information: https://graphviz.org  ## Contributing  If you want to contribute to this project, please get involved. You can do so in three ways:  1. **To discuss the current implementation and discuss potential changes**, file a ‘GitHub’ issue [here](https://github.com/cjvanlissa/empirical_cycle/issues) 2. **To directly propose changes**, send a pull request containing the proposed changes [here](https://github.com/cjvanlissa/tidySEM/pulls) 3. **To create a derivative theory**, please fork the repository [here](https://github.com/cjvanlissa/empirical_cycle/fork). Please cite this repository (see below), and add this repository as a related work (below and by adding the appropriate metadata on Zenodo).  By participating in this project, you agree to abide by the [Contributor Covenant](https://www.contributor-covenant.org/version/2/0/code_of_conduct.html).  ## Related Works  See this project's Zenodo page for cross-references to related work.   This repository contains an implementation of the \"empirical cycle\", a model proposed by De Groot and Spiekerman (1969, p. 28)  > De Groot, A. D., & Spiekerman, J. A. A. (1969). Methodology: Foundations of > inference and research in the behavioral sciences. De Gruyter Mouton. > https://doi.org/10.1515/9783112313121  ## Citing this work  See [this project's Zenodo page](https://doi.org/10.5281/zenodo.14552329) for the preferred citation."},{"path":"https://cjvanlissa.github.io/theorytools/articles/updating_theory.html","id":"step-1-accessing-an-existing-theory","dir":"Articles","previous_headings":"","what":"Step 1: Accessing an Existing Theory","title":"Updating a Theory","text":"describe two cases: one theory archived Zenodo, one theory also archived GitHub.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/updating_theory.html","id":"a-theory-on-zenodo","dir":"Articles","previous_headings":"Step 1: Accessing an Existing Theory","what":"A Theory on Zenodo","title":"Updating a Theory","text":"theory exists Zenodo, can download local copy running code , demonstrated Morris’ Tripartite Model (see vignette). Change path directory hard drive want store theory.","code":"download_theory(   id = \"https://doi.org/10.5281/zenodo.14921521\",   path = \"c:/theories/tripartite_downloaded\")"},{"path":"https://cjvanlissa.github.io/theorytools/articles/updating_theory.html","id":"a-theory-on-github","dir":"Articles","previous_headings":"Step 1: Accessing an Existing Theory","what":"A Theory on GitHub","title":"Updating a Theory","text":"Navigate GitHub repository FAIR theory want update. Click Fork button upper right corner create copy repository GitHub account (information, see GitHub documentation). gives space experiment propose changes without affecting original repository. ’ve forked repository, clone local machine running following code R (see information):","code":"download_theory(   id = \"https://github.com/cjvanlissa/tripartite_model.git\",   path = \"c:/theories/tripartite_clone\")"},{"path":"https://cjvanlissa.github.io/theorytools/articles/updating_theory.html","id":"step-2-make-changes-to-the-theory","dir":"Articles","previous_headings":"","what":"Step 2: Make Changes to the Theory","title":"Updating a Theory","text":"can now: Edit theory implementation (e.g., tripartite_model.txt, files theory implemented, see README ’re sure files ) Modify expand README Update metadata ontology elements Add documentation related materials Increment version number theory Track changes using Git, push changes GitHub repository running:","code":"worcs::git_update(\"Describe your changes to the theory.\")"},{"path":"https://cjvanlissa.github.io/theorytools/articles/updating_theory.html","id":"step-3-optional-create-a-pull-request","dir":"Articles","previous_headings":"","what":"Step 3 (Optional): Create a Pull Request","title":"Updating a Theory","text":"’d like original authors consider incorporating updates main project: Go forked repository GitHub. Click “Compare & pull request” (see information) Write short message explaining changes motivation. Submit pull request. maintainers original theory can review suggestions decide whether merge .","code":""},{"path":"https://cjvanlissa.github.io/theorytools/articles/updating_theory.html","id":"step-4-optional-create-an-independent-fair-theory","dir":"Articles","previous_headings":"","what":"Step 4 (Optional): Create an Independent FAIR Theory","title":"Updating a Theory","text":"Sometimes theories branch go separate way; case theory, follow steps vignette) archive FAIR theory Zenodo. Importantly, FAIR theory originated previous FAIR theory, document predecessor metadata. , edit theory’s metadata. Related works field, add DOI theory’s predecessor. Relation field, select derived .","code":""},{"path":"https://cjvanlissa.github.io/theorytools/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Caspar J. Van Lissa. Author, maintainer.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Van Lissa CJ (2026). theorytools: FAIR Theory Construction. R package version 0.1.2, https://cjvanlissa.github.io/theorytools/.","code":"@Manual{,   title = {theorytools: FAIR Theory Construction},   author = {Caspar J. {Van Lissa}},   year = {2026},   note = {R package version 0.1.2},   url = {https://cjvanlissa.github.io/theorytools/}, }"},{"path":"https://cjvanlissa.github.io/theorytools/index.html","id":"theorytools","dir":"","previous_headings":"","what":"FAIR Theory Construction","title":"FAIR Theory Construction","text":"theorytools package offers integrated suite tools creating, maintaining, reusing FAIR (Findable, Accessible, Interoperable, Reusable) theories R. Designed support transparent collaborative theory development, package enables users formalize theories, track changes version control, assess pre-empirical coherence, derive testable hypotheses. Aligning open science principles workflows, theorytools facilitates systematic improvement theoretical frameworks enhances discoverability usability.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"FAIR Theory Construction","text":"can install development version theorytools GitHub :","code":"# install.packages(\"pak\") pak::pak(\"cjvanlissa/theorytools\")"},{"path":"https://cjvanlissa.github.io/theorytools/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"FAIR Theory Construction","text":"View package website . Every user-facing function package documented, documentation can accessed running ?function_name R console, e.g., ?create_fair_theory. Moreover, can check package vignettes running vignette(package = \"theorytools\"), read specific vignettes running, e.g., vignette(\"fairtheory\", package = \"theorytools\").","code":""},{"path":"https://cjvanlissa.github.io/theorytools/index.html","id":"citing-theorytools","dir":"","previous_headings":"","what":"Citing theorytools","title":"FAIR Theory Construction","text":"can cite R-package following citation: Van Lissa, C. J. (2024). FAIR Theory Construction Toolkit (0.1.0) [R package]. https://github.com/cjvanlissa/theorytools","code":""},{"path":"https://cjvanlissa.github.io/theorytools/index.html","id":"contributing-and-contact-information","dir":"","previous_headings":"","what":"Contributing and Contact Information","title":"FAIR Theory Construction","text":"ideas, please get involved. can contribute opening issue GitHub, sending pull request proposed features. Contributions code must adhere tidyverse style guide. File GitHub issue Make pull request participating project, agree abide Contributor Code Conduct v2.0.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_readme_fair_theory.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Readme File — add_readme_fair_theory","title":"Add Readme File — add_readme_fair_theory","text":"Writes README file specific path.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_readme_fair_theory.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Readme File — add_readme_fair_theory","text":"","code":"add_readme_fair_theory(path, title, ...)"},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_readme_fair_theory.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Readme File — add_readme_fair_theory","text":"path Character, indicating directory create FAIR theory. title Character, indicating theory title. Default: NULL ... Additional arguments passed functions.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_readme_fair_theory.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Readme File — add_readme_fair_theory","text":"Invisibly returns logical value, indicating whether function successful .","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_readme_fair_theory.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Readme File — add_readme_fair_theory","text":"","code":"add_readme_fair_theory(path = tempdir(), title = \"My Theory\")"},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_significance.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Significance Asterisks — add_significance","title":"Add Significance Asterisks — add_significance","text":"Given data.frame column containing p-values two columns containing lower- upper bounds confidence interval, adds column significance asterisks.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_significance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Significance Asterisks — add_significance","text":"","code":"add_significance(x, p_column = NULL, ci_lb = NULL, ci_up = NULL, alpha = 0.05)"},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_significance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Significance Asterisks — add_significance","text":"x data.frame p_column Atomic character, referring name column p-values. provided, confidence interval ignored. Default: NULL ci_lb Atomic character, referring name column lower bound confidence interval. Default: NULL ci_up Atomic character, referring name column upper bound confidence interval. Default: NULL alpha Significance level, default: .05","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_significance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Significance Asterisks — add_significance","text":"data.frame","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_significance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Significance Asterisks — add_significance","text":"","code":"tmp <- add_significance(head(iris))"},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_theory_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Theory File — add_theory_file","title":"Add Theory File — add_theory_file","text":"Writes theory file specific path.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_theory_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Theory File — add_theory_file","text":"","code":"add_theory_file(path, theory_file = \"theory.txt\")"},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_theory_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Theory File — add_theory_file","text":"path Character, indicating directory create FAIR theory. theory_file Character, referring existing theory file(s) copied, new theory file created. Default NULL nothing.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_theory_file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Theory File — add_theory_file","text":"Invisibly returns logical value, indicating whether function successful .","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_theory_file.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Theory File — add_theory_file","text":"","code":"add_theory_file(path = tempdir(), theory_file = \"theory.txt\")"},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_to_pkgdown.html","id":null,"dir":"Reference","previous_headings":"","what":"Add webexercises helper files to pkgdown — add_to_pkgdown","title":"Add webexercises helper files to pkgdown — add_to_pkgdown","text":"Adds necessary helper files existing pkgdown project.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_to_pkgdown.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add webexercises helper files to pkgdown — add_to_pkgdown","text":"","code":"add_to_pkgdown(pkgdown_dir = \".\")"},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_to_pkgdown.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add webexercises helper files to pkgdown — add_to_pkgdown","text":"pkgdown_dir base directory pkgdown project","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_to_pkgdown.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add webexercises helper files to pkgdown — add_to_pkgdown","text":"return value, called side effects.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_zenodo_json.html","id":null,"dir":"Reference","previous_headings":"","what":"Add 'Zenodo' JSON File — add_zenodo_json","title":"Add 'Zenodo' JSON File — add_zenodo_json","text":"Writes '.zenodo.json' file specified path. Writes README file specific path.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_zenodo_json.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add 'Zenodo' JSON File — add_zenodo_json","text":"","code":"add_zenodo_json(path, title, upload_type, keywords)  add_zenodo_json_theory(path, title, keywords)"},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_zenodo_json.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add 'Zenodo' JSON File — add_zenodo_json","text":"path Character, indicating directory create FAIR theory. title Character, indicating theory title. Default: NULL upload_type Character, indicating upload type. keywords Character vector keywords.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_zenodo_json.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add 'Zenodo' JSON File — add_zenodo_json","text":"Invisibly returns logical value, indicating whether function successful .","code":""},{"path":[]},{"path":"https://cjvanlissa.github.io/theorytools/reference/add_zenodo_json.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add 'Zenodo' JSON File — add_zenodo_json","text":"","code":"add_zenodo_json(path = tempdir(), title = \"Theory Title\",                 upload_type = \"software\", keywords = \"R\") add_zenodo_json_theory(path = tempdir(), title = \"My Theory\",                        keywords = \"secondkeyword\") add_zenodo_json_theory(path = tempdir(), title = \"My Theory\",                        keywords = c(\"secondkeyword\", \"thirdkeyword\"))"},{"path":"https://cjvanlissa.github.io/theorytools/reference/code.html","id":null,"dir":"Reference","previous_headings":"","what":"Code Text Data — code","title":"Code Text Data — code","text":"Create reproducible script coding qualitative text data sequentially assigning elements x specific labels.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/code.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Code Text Data — code","text":"","code":"code(x, ...)  # S3 method for class 'character' code(x, similarity = c(\"stringdist\", \"embeddings\"), ...)  # S3 method for class 'code_list' code(x, label = NULL, ...)  add_level(x, similarity = NULL, ...)"},{"path":"https://cjvanlissa.github.io/theorytools/reference/code.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Code Text Data — code","text":"x object method exists. ... Additional arguments passed functions. similarity method use compute similarity entries. Defaults \"stringdist\", uses stringdistmatrix. Option \"embeddings\" additionally requires passing named argument \"model_path\", point LLM downloaded download_huggingface. label Label assign elements identified via numeric indexing, passed via ....","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/code.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Code Text Data — code","text":"list class code_list.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/code.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Code Text Data — code","text":"add_level(): case nested coding, use add_level() add level coding code_list object.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/code.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Code Text Data — code","text":"","code":"x <- c(\"autonomy [satisfaction] increases\", \"competence [satisfaction] increases\", \"relatedness [satisfaction] increases\" , \"motivation is more internalized\", \"motivation is more internalized\", \"motivation is more internalized1\", \"event is more controlling\", \"event is more controlling\", \"event communicates more effectance information\") coded <- code(x) coded <- code(coded, \"need_satisfaction\", 1:3) coded <- code(coded, \"internalization\", 1:3) coded <- code(coded, \"functional_significance\", 1:3) coded <- add_level(coded) coded <- code(coded, \"random_level1\", 1:2) coded <- code(coded, \"random_level2\", 1) coded #> No more unassigned items."},{"path":"https://cjvanlissa.github.io/theorytools/reference/create_fair_theory.html","id":null,"dir":"Reference","previous_headings":"","what":"Create FAIR Theory Repository — create_fair_theory","title":"Create FAIR Theory Repository — create_fair_theory","text":"Partly automates process creating FAIR theory repository, see Details.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/create_fair_theory.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create FAIR Theory Repository — create_fair_theory","text":"","code":"create_fair_theory(   path,   title = NULL,   theory_file = NULL,   remote_repo = NULL,   add_license = \"cc0\",   ... )"},{"path":"https://cjvanlissa.github.io/theorytools/reference/create_fair_theory.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create FAIR Theory Repository — create_fair_theory","text":"path Character, indicating directory create FAIR theory. title Character, indicating theory title. Default: NULL theory_file Character, referring existing theory file(s) copied, new theory file created. Default NULL nothing. remote_repo Name 'GitHub' repository exists created current authenticated user's account, see gh_whoami, Default: NULL add_license PARAM_DESCRIPTION, Default: 'cc0' ... Additional arguments passed functions.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/create_fair_theory.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create FAIR Theory Repository — create_fair_theory","text":"Invisibly returns logical value, indicating whether function successful .","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/create_fair_theory.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create FAIR Theory Repository — create_fair_theory","text":"following steps executed sequentially: Create project folder path Initialize local 'Git' repository path remote_repo refers user's existing 'GitHub' repository, add remote local 'Git' repository. Otherwise, create new 'GitHub' repository name add remote. Add theory file. theory_file refers existing file, copy path. theory_file refers new file, create path. Add license named add_license Add README.md file Add 'Zenodo' metadata recognizes repository FAIR theory possible push remote repository, use git_update push repository 'GitHub'","code":""},{"path":[]},{"path":"https://cjvanlissa.github.io/theorytools/reference/create_fair_theory.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create FAIR Theory Repository — create_fair_theory","text":"","code":"# Create a theory with no remote repository (for safe testing) theory_dir <- file.path(tempdir(), \"theory\") create_fair_theory(path = theory_dir,                    title = \"This is My Theory\",                    theory_file = \"theory.txt\",                    remote_repo = NULL,                    add_license = \"cc0\")  # Create a theory with a remote repository if (FALSE) { # \\dontrun{ theory_dir <- file.path(tempdir(), \"theory_github\") out <- create_fair_theory(path = theory_dir,                           title = \"This is My GitHub Theory\",                           theory_file = \"theory.txt\",                           remote_repo = \"delete_test\",                           add_license = \"ccby\") } # }"},{"path":"https://cjvanlissa.github.io/theorytools/reference/derive_formula.html","id":null,"dir":"Reference","previous_headings":"","what":"Derive Formulae From Augmented DAG — derive_formula","title":"Derive Formulae From Augmented DAG — derive_formula","text":"Uses form attribute edges augmented DAG construct formulae relationship exposure outcome.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/derive_formula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Derive Formulae From Augmented DAG — derive_formula","text":"","code":"derive_formula(x, exposure, outcome, data = NULL, ...)"},{"path":"https://cjvanlissa.github.io/theorytools/reference/derive_formula.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Derive Formulae From Augmented DAG — derive_formula","text":"x object class dagitty. exposure Atomic character, indicating exposure node x. outcome Atomic character, indicating outcome node x. data Optional, data.frame used environment formulae. Default: NULL ... Additional arguments, passed adjustmentSets","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/derive_formula.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Derive Formulae From Augmented DAG — derive_formula","text":"list objects class formula.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/derive_formula.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Derive Formulae From Augmented DAG — derive_formula","text":"form attribute augmented DAG class dagitty contain information functional form relationships specified DAG. function, form attribute must additive function also accepted formula. form attribute may contain leading intercept constant slopes, parsed . form attribute meet requirements, resulting formula may invalid. example: form=\".5+x1\" return ~x1. form=\"2*x1*x2\" return ~x1+x2+x1:x2. form=\"-.2-.2*(x3^2)\" return ~(x3^2).","code":""},{"path":[]},{"path":"https://cjvanlissa.github.io/theorytools/reference/derive_formula.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Derive Formulae From Augmented DAG — derive_formula","text":"","code":"x <- dagitty::dagitty('dag { C O X Y O <- X [form=\"I(X^2)\"] C -> X Y -> O [form=\"Y*X\"] }') f1 <- derive_formula(x, outcome = \"O\", exposure = \"X\") f2 <- derive_formula(x, outcome = \"O\", exposure = \"Y\")"},{"path":"https://cjvanlissa.github.io/theorytools/reference/download_huggingface.html","id":null,"dir":"Reference","previous_headings":"","what":"Download 'Hugging Face' Model — download_huggingface","title":"Download 'Hugging Face' Model — download_huggingface","text":"Download model 'Hugging Face' local folder, used e.g. get_embeddings.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/download_huggingface.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download 'Hugging Face' Model — download_huggingface","text":"","code":"download_huggingface(model, path, ...)"},{"path":"https://cjvanlissa.github.io/theorytools/reference/download_huggingface.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download 'Hugging Face' Model — download_huggingface","text":"model Atomic character, referencing model - typically form \"user/model\". path Atomic character, referencing local folder model installed. ... Arguments passed functions.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/download_huggingface.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download 'Hugging Face' Model — download_huggingface","text":"succes: Atomic character, path local model. failure: NULL.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/download_theory.html","id":null,"dir":"Reference","previous_headings":"","what":"Download FAIR Theory — download_theory","title":"Download FAIR Theory — download_theory","text":"Downloads FAIR theory archive 'Git' remote repository 'Zenodo'.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/download_theory.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download FAIR Theory — download_theory","text":"","code":"download_theory(id, path = \".\")"},{"path":"https://cjvanlissa.github.io/theorytools/reference/download_theory.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download FAIR Theory — download_theory","text":"id URL 'Git' repository DOI 'Zenodo' archive. path Character, indicating directory create FAIR theory.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/download_theory.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download FAIR Theory — download_theory","text":"","code":"download_theory(id = \"https://github.com/cjvanlissa/tripartite_model.git\", path = file.path(tempdir(), \"tripartite_git\")) download_theory(id = \"10.5281/zenodo.14921521\", path = file.path(tempdir(), \"tripartite_zenodo\"))"},{"path":"https://cjvanlissa.github.io/theorytools/reference/filter_conditional_independencies.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter Conditional Independencies — filter_conditional_independencies","title":"Filter Conditional Independencies — filter_conditional_independencies","text":"Removes conditional independencies, obtained using impliedConditionalIndependencies, based variables available data.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/filter_conditional_independencies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter Conditional Independencies — filter_conditional_independencies","text":"","code":"filter_conditional_independencies(x, data)"},{"path":"https://cjvanlissa.github.io/theorytools/reference/filter_conditional_independencies.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter Conditional Independencies — filter_conditional_independencies","text":"x object class dagitty.cis. data data.frame.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/filter_conditional_independencies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter Conditional Independencies — filter_conditional_independencies","text":"object class dagitty.cis, NULL conditional independencies remain.","code":""},{"path":[]},{"path":"https://cjvanlissa.github.io/theorytools/reference/filter_conditional_independencies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter Conditional Independencies — filter_conditional_independencies","text":"","code":"dag <- dagitty::dagitty('dag { x1 -> y x2 -> y}') df <- data.frame(x1 = rnorm(10), y = rnorm(10)) cis <- dagitty::impliedConditionalIndependencies(dag) cis <- filter_conditional_independencies(cis, df) is.null(cis) #> [1] TRUE"},{"path":"https://cjvanlissa.github.io/theorytools/reference/get_embeddings.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Vector Embeddings (uses Python) — get_embeddings","title":"Get Vector Embeddings (uses Python) — get_embeddings","text":"function wraps 'transformers' library 'Python', obtain vector embeddings (numerical representation meaning) character vector based pretrained model.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/get_embeddings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Vector Embeddings (uses Python) — get_embeddings","text":"","code":"get_embeddings(x, model_path = NULL)"},{"path":"https://cjvanlissa.github.io/theorytools/reference/get_embeddings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Vector Embeddings (uses Python) — get_embeddings","text":"x Character vector text embedded. model_path Atomic character vector referring folder pretrained model. Default: NULL","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/get_embeddings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Vector Embeddings (uses Python) — get_embeddings","text":"Matrix","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/get_embeddings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Vector Embeddings (uses Python) — get_embeddings","text":"","code":"if (FALSE) { # \\dontrun{ if(requireNamespace(\"reticulate\", quietly = TRUE)){  tmp <- get_embeddings(c(\"cat\", \"my cat\", \"dog\"),  model_path = \"scibert_scivocab_uncased\")  } } # }"},{"path":"https://cjvanlissa.github.io/theorytools/reference/lsac.html","id":null,"dir":"Reference","previous_headings":"","what":"Synthetic Data: Longitudinal Study of Australian Children — lsac","title":"Synthetic Data: Longitudinal Study of Australian Children — lsac","text":"synthetic dataset, based \"Growing Australia - Longitudinal Study Australian Children\" (LSAC). longitudinal study covers representative sample 10.000 children families, aims examine children's development early childhood adolescence adulthood. variables pertain mother; note fathers also play important sometimes unique role children's emotional development.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/lsac.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Synthetic Data: Longitudinal Study of Australian Children — lsac","text":"","code":"data(lsac)"},{"path":"https://cjvanlissa.github.io/theorytools/reference/lsac.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Synthetic Data: Longitudinal Study of Australian Children — lsac","text":"data frame 8214 rows 6 variables.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/lsac.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Synthetic Data: Longitudinal Study of Australian Children — lsac","text":"Except \"coping\", variables created taking row means several items, omitting missing values. corresponding item names LSAC codebook given .","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/lsac.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Synthetic Data: Longitudinal Study of Australian Children — lsac","text":"Australian Institute Family Studies. (2020, March 23). Growing Australia.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/mottistefanidi2012.html","id":null,"dir":"Reference","previous_headings":"","what":"Adaptation of Adolescent Immigrants in Greece — mottistefanidi2012","title":"Adaptation of Adolescent Immigrants in Greece — mottistefanidi2012","text":"simulated dataset, based work Motti-Stefanidi colleagues (2012), assesses adaptation well-adolescent immigrants Greek schools.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/mottistefanidi2012.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adaptation of Adolescent Immigrants in Greece — mottistefanidi2012","text":"","code":"data(mottistefanidi2012)"},{"path":"https://cjvanlissa.github.io/theorytools/reference/mottistefanidi2012.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Adaptation of Adolescent Immigrants in Greece — mottistefanidi2012","text":"data frame 1057 rows 17 variables.","code":""},{"path":[]},{"path":"https://cjvanlissa.github.io/theorytools/reference/mottistefanidi2012.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Adaptation of Adolescent Immigrants in Greece — mottistefanidi2012","text":"Motti-Stefanidi, F., Asendorpf, J. B., & Masten, . S. (2012). adaptation well-adolescent immigrants Greek schools: multilevel, longitudinal study risks resources. Development Psychopathology, 24(2), 451–473. doi:10.1017/S0954579412000090","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/prune_dag.html","id":null,"dir":"Reference","previous_headings":"","what":"Prune DAG Based on Adjustment Sets — prune_dag","title":"Prune DAG Based on Adjustment Sets — prune_dag","text":"Wraps adjustmentSets construct pruned DAG includes covariates (asymptotically) allow unbiased estimation causal effects interest.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/prune_dag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prune DAG Based on Adjustment Sets — prune_dag","text":"","code":"prune_dag(   x,   exposure = NULL,   outcome = NULL,   which_set = c(\"first\", \"sample\", \"all\"),   ... )"},{"path":"https://cjvanlissa.github.io/theorytools/reference/prune_dag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prune DAG Based on Adjustment Sets — prune_dag","text":"x input graph class dagitty. exposure Atomic character, name exposure variable. outcome Atomic character, name outcome variable. which_set Atomic character, indicating set covariates select case multiple. Valid choices c(\"first\", \"sample\", \"\"), see Value. ... arguments passed adjustmentSets","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/prune_dag.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prune DAG Based on Adjustment Sets — prune_dag","text":"which_set = \"\", returns list data.frames allow sensitivity analyses. Otherwise, returns data.frame.","code":""},{"path":[]},{"path":"https://cjvanlissa.github.io/theorytools/reference/prune_dag.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prune DAG Based on Adjustment Sets — prune_dag","text":"","code":"dag <- dagitty::dagitty('dag {x -> y}') prune_dag(dag, exposure = \"x\", outcome = \"y\") #> dag { #> x #> y #> x -> y #> }"},{"path":"https://cjvanlissa.github.io/theorytools/reference/quizz.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Quiz — quizz","title":"Create a Quiz — quizz","text":"Convenience function creating basic quiz HTML format arguments captured ..., type question determined automatically class arguments.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/quizz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Quiz — quizz","text":"","code":"quizz(   ...,   render_if = knitr::is_html_output(),   title = \"Quiz\",   show_box = TRUE,   show_check = TRUE )"},{"path":"https://cjvanlissa.github.io/theorytools/reference/quizz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Quiz — quizz","text":"... argument named vector, see Details. render_if Logical, whether render output. default, argument uses knitr::is_html_output(). title Atomic character, default: 'Quiz' show_box Logical, whether draw box around quiz. Default: TRUE show_check Logical, whether show button check answers. Default: TRUE","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/quizz.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Quiz — quizz","text":"NULL, function called side effect printing HTML code using cat().","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/quizz.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a Quiz — quizz","text":"function renders questions captured arguments .... name argument text question. value argument determined question type correct answer. following types questions supported: \"torf()\" argument single value type logical, e.g.: \"answer question true.\" = TRUE \"mcq()\" argument vector type character. first element taken correct answer; order answers randomized. E.g.: \"multiple choice question three answers.\" = c(\"Correct\", \"Incorrect\", \"sure\") \"fitb()\" argument type numeric. vector atomic, first element taken correct answer, e.g.: \"Provide exact floating point answer 0.81\" = 0.81. vector two elements, second element taken tolerance tol, e.g.: \", 0.8 correct.\" = c(0.81, 0.01). vector type integer, tolerance set zero, e.g.: \"answer 4.\" = 4L Alternatively, ... may contain single atomic character referring text file contains questions, see examples.","code":""},{"path":[]},{"path":"https://cjvanlissa.github.io/theorytools/reference/quizz.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Quiz — quizz","text":"","code":"# Quiz from arguments: invisible(capture.output(theorytools:::quizz( \"The answer to this question is true.\" = TRUE, \"This multiple choice question has three answers.\" =  c(answer = \"Correct\", \"Incorrect\", \"Not sure\"), \"Provide an exact floating point answer of 0.81\" = 0.81, render_if = TRUE ))) # From a file: quizz_file <- tempfile() writeLines( c(\"The answer is true. = TRUE\", \"The answer is correct = c(answer = \\\"Correct\\\", \\\"Incorrect\\\", \\\"Not sure\\\")\", \"The answer is exactly .81 = 0.81\", \"But here, .8 is also fine = c(0.81, .01)\", \"Write the word 'true' = c('true', 'TRUE')\", \"Here, answer exactly 4. = 4L\") , quizz_file) invisible(capture.output(theorytools:::quizz(quizz_file, render_if = TRUE)))"},{"path":"https://cjvanlissa.github.io/theorytools/reference/select_controls.html","id":null,"dir":"Reference","previous_headings":"","what":"Select Covariate Adjustment Sets from Data — select_controls","title":"Select Covariate Adjustment Sets from Data — select_controls","text":"Wraps adjustmentSets construct dataset covariates (asymptotically) allow unbiased estimation causal effects observational data.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/select_controls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select Covariate Adjustment Sets from Data — select_controls","text":"","code":"select_controls(   x,   data,   exposure = NULL,   outcome = NULL,   which_set = c(\"first\", \"sample\", \"all\"),   ... )"},{"path":"https://cjvanlissa.github.io/theorytools/reference/select_controls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select Covariate Adjustment Sets from Data — select_controls","text":"x input graph class dagitty. data data.frame object coercible .data.frame(). exposure Atomic character, name exposure variable. outcome Atomic character, name outcome variable. which_set Atomic character, indicating set covariates select case multiple. Valid choices c(\"first\", \"sample\", \"\"), see Value. ... arguments passed adjustmentSets","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/select_controls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select Covariate Adjustment Sets from Data — select_controls","text":"which_set = \"\", returns list data.frames allow sensitivity analyses. Otherwise, returns data.frame.","code":""},{"path":[]},{"path":"https://cjvanlissa.github.io/theorytools/reference/select_controls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select Covariate Adjustment Sets from Data — select_controls","text":"","code":"dag <- dagitty::dagitty('dag {x -> y}') df <- data.frame(x = rnorm(10), y = rnorm(10)) df1 <- select_controls(dag, df, exposure = \"x\", outcome = \"y\") class(df1) == \"data.frame\" #> [1] TRUE df2 <- select_controls(dag, df, exposure = \"x\", outcome = \"y\", which_set = \"sample\") class(df2) == \"data.frame\" #> [1] TRUE lst1 <- select_controls(dag, df, exposure = \"x\", outcome = \"y\", which_set = \"all\") class(lst1) == \"list\" #> [1] TRUE"},{"path":"https://cjvanlissa.github.io/theorytools/reference/similarity_cosine.html","id":null,"dir":"Reference","previous_headings":"","what":"Cosine Similarity — similarity_cosine","title":"Cosine Similarity — similarity_cosine","text":"Compute cosine similarity rows matrix.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/similarity_cosine.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cosine Similarity — similarity_cosine","text":"","code":"similarity_cosine(x)"},{"path":"https://cjvanlissa.github.io/theorytools/reference/similarity_cosine.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cosine Similarity — similarity_cosine","text":"x Numeric matrix, rows cases columns features.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/similarity_cosine.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cosine Similarity — similarity_cosine","text":"matrix","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/similarity_cosine.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cosine Similarity — similarity_cosine","text":"","code":"set.seed(1) similarity_cosine(matrix(runif(30), nrow = 3)) #>           [,1]      [,2]      [,3] #> [1,] 1.0000000 0.7817204 0.8946771 #> [2,] 0.7817204 1.0000000 0.8068776 #> [3,] 0.8946771 0.8068776 1.0000000"},{"path":"https://cjvanlissa.github.io/theorytools/reference/similarity_stringdist.html","id":null,"dir":"Reference","previous_headings":"","what":"String Similarity — similarity_stringdist","title":"String Similarity — similarity_stringdist","text":"Wraps stringdistmatrix return string similarity matrix (e.g., use code).","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/similarity_stringdist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"String Similarity — similarity_stringdist","text":"","code":"similarity_stringdist(x, ...)"},{"path":"https://cjvanlissa.github.io/theorytools/reference/similarity_stringdist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"String Similarity — similarity_stringdist","text":"x Character vector. ... Arguments passed stringdistmatrix.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/similarity_stringdist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"String Similarity — similarity_stringdist","text":"matrix","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/similarity_stringdist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"String Similarity — similarity_stringdist","text":"","code":"similarity_stringdist(c(\"cat\", \"a cat\", \"dog\")) #>       cat a cat dog #> cat   1.0   0.6 0.4 #> a cat 0.6   1.0 0.0 #> dog   0.4   0.0 1.0"},{"path":"https://cjvanlissa.github.io/theorytools/reference/simulate_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate Data from DAG — simulate_data","title":"Simulate Data from DAG — simulate_data","text":"Simulates data (augmented) DAG, respecting optional metadata fields form, functional form relationships, distribution, distributions exogenous nodes residuals.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/simulate_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate Data from DAG — simulate_data","text":"","code":"simulate_data(   x,   beta_default = round(runif(1, min = -0.6, max = 0.6), 2),   n = 500,   run = TRUE,   duplicated = \"unique\" )"},{"path":"https://cjvanlissa.github.io/theorytools/reference/simulate_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate Data from DAG — simulate_data","text":"x object class dagitty. beta_default Function used specify missing edge coefficients. Default: runif(1, min = -0.6, max = 0.6) n Atomic integer defining sample size, default: 500 run Logical, indicating whether run simulation. Default: TRUE. duplicated Atomic character, indicating resolve duplicate terms multiple edges pointing node. Default: \"unique\". See Details.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/simulate_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate Data from DAG — simulate_data","text":"run TRUE, function returns data.frame additional attribute called attr( , = \"script\") contains script simulating data. run FALSE, function returns script character vector.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/simulate_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate Data from DAG — simulate_data","text":"Data simulated sequentially, first exogenous nodes descendants. x augmented DAG metadata indicating functional form relationships distribution exogenous nodes residuals, information used. information absent, nodes residuals assumed normally distributed, edges assumed linear, coefficients samples based beta_default. argument duplicated controls multiplicative terms merged across edges pointing outcome node. default duplicated = \"unique\" removes terms duplicated across edges (.e., two edges point node \"O\", edges specify .5*E, resulting function say .5*E. However, one edge specifies .2*E specifies .3*E, duplicated added. Alternatively, duplicated = \"add\" just sums terms across edges pointing outcome node.","code":""},{"path":[]},{"path":"https://cjvanlissa.github.io/theorytools/reference/simulate_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate Data from DAG — simulate_data","text":"","code":"x <- dagitty::dagitty(' dag {   X [distribution=\"rbinom(size = 2, prob = .5)\"]   Z [distribution=\"rexp()\"]   Y [distribution=\"rnorm()\"]    X -> Y [form=\"0.5+X\"]   Z -> Y [form=\"2*Z\"]   A -> X } ') txt <- simulate_data(x, n = 5, run = FALSE) df <- simulate_data(x, n = 5, run = TRUE) df_from_txt <- eval(parse(text = txt))"},{"path":"https://cjvanlissa.github.io/theorytools/reference/use_webex_vignette.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a webexercises vignette — use_webex_vignette","title":"Create a webexercises vignette — use_webex_vignette","text":"Wraps use_vignette add vignette article vignettes/ support webexercises.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/use_webex_vignette.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a webexercises vignette — use_webex_vignette","text":"","code":"use_webex_vignette(name, title = NULL, type = c(\"vignette\", \"article\"))"},{"path":"https://cjvanlissa.github.io/theorytools/reference/use_webex_vignette.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a webexercises vignette — use_webex_vignette","text":"name Atomic character, vignette name. See use_vignette. title Atomic character, vignette title. See use_vignette. type Atomic character, one c(\"vignette\", \"article\"), defaults \"vignette\".","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/use_webex_vignette.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a webexercises vignette — use_webex_vignette","text":"Returns NULL invisibly, called side effects.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/use_webex_vignette.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a webexercises vignette — use_webex_vignette","text":"","code":"if (FALSE) { # \\dontrun{ use_webex_vignette(\"vignette_with_quiz.Rmd\", \"Quiz people with webexercises\") } # }"},{"path":"https://cjvanlissa.github.io/theorytools/reference/webex_vignette.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Vignette with webexercises Support — webex_vignette","title":"Create Vignette with webexercises Support — webex_vignette","text":"function wraps rmarkdown::html_document configure compilation embed default webexercises CSS JavaScript files resulting HTML.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/webex_vignette.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Vignette with webexercises Support — webex_vignette","text":"","code":"webex_vignette(...)"},{"path":"https://cjvanlissa.github.io/theorytools/reference/webex_vignette.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Vignette with webexercises Support — webex_vignette","text":"... Additional function arguments pass html_document.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/webex_vignette.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Vignette with webexercises Support — webex_vignette","text":"R Markdown output format pass 'render'.","code":""},{"path":"https://cjvanlissa.github.io/theorytools/reference/webex_vignette.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create Vignette with webexercises Support — webex_vignette","text":"Call function output_format argument render function compiling HTML documents RMarkdown source.","code":""},{"path":[]},{"path":"https://cjvanlissa.github.io/theorytools/news/index.html","id":"theorytools-012","dir":"Changelog","previous_headings":"","what":"theorytools 0.1.2","title":"theorytools 0.1.2","text":"CRAN release: 2025-07-13 Minor bugfixes Add prune_dag() Add vignette computational_social_science.Rmd","code":""},{"path":"https://cjvanlissa.github.io/theorytools/news/index.html","id":"theorytools-011","dir":"Changelog","previous_headings":"","what":"theorytools 0.1.1","title":"theorytools 0.1.1","text":"CRAN release: 2025-06-23 Add several vignettes accompany paper release","code":""},{"path":"https://cjvanlissa.github.io/theorytools/news/index.html","id":"theorytools-010","dir":"Changelog","previous_headings":"","what":"theorytools 0.1.0","title":"theorytools 0.1.0","text":"CRAN release: 2025-01-14 Initial CRAN submission.","code":""}]
